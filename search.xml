<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>maven版本区分</title>
    <url>/2019/07/22/basics/maven_version/</url>
    <content><![CDATA[<h3 id="maven的快照版本和发布版本"><a href="#maven的快照版本和发布版本" class="headerlink" title="maven的快照版本和发布版本"></a>maven的快照版本和发布版本</h3><p>在使用maven过程中，我们在开发阶段经常性的会有很多公共库处于不稳定状态，随时需要修改并发布，可能一天就要发布一次，遇到bug时，甚至一天要发布N次。我们知道，maven的依赖管理是基于版本管理的，对于发布状态的artifact，如果版本号相同，即使我们内部的镜像服务器上的组件比本地新，maven也不会主动下载的。如果我们在开发阶段都是基于正式发布版本来做依赖管理，那么遇到这个问题，就需要升级组件的版本号，可这样就明显不符合要求和实际情况了。但是，如果是基于快照版本，那么问题就自热而然的解决了，而maven已经为我们准备好了这一切。<br>      maven中的仓库分为两种，snapshot快照仓库和release发布仓库。snapshot快照仓库用于保存开发过程中的不稳定版本，release正式仓库则是用来保存稳定的发行版本。定义一个组件/模块为快照版本，只需要在pom文件中在该模块的版本号后加上-SNAPSHOT即可(注意这里必须是大写)，如下： </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;groupId&gt;cc.mzone&lt;&#x2F;groupId&gt;</span><br><span class="line">&lt;artifactId&gt;m1&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;version&gt;0.1-SNAPSHOT&lt;&#x2F;version&gt;</span><br><span class="line">&lt;packaging&gt;jar&lt;&#x2F;packaging&gt;</span><br></pre></td></tr></table></figure>
<p>maven2会根据模块的版本号(pom文件中的version)中是否带有-SNAPSHOT来判断是快照版本还是正式版本。如果是快照版本，那么在mvn deploy时会自动发布到快照版本库中，会覆盖老的快照版本，而在使用快照版本的模块，在不更改版本号的情况下，直接编译打包时，maven会自动从镜像服务器上下载最新的快照版本。如果是正式发布版本，那么在mvn deploy时会自动发布到正式版本库中，而使用正式版本的模块，在不更改版本号的情况下，编译打包时如果本地已经存在该版本的模块则不会主动去镜像服务器上下载。<br>所以，我们在开发阶段，可以将公用库的版本设置为快照版本，而被依赖组件则引用快照版本进行开发，在公用库的快照版本更新后，我们也不需要修改pom文件提示版本号来下载新的版本，直接mvn执行相关编译、打包命令即可重新下载最新的快照库了，从而也方便了我们进行开发。<br>目前在JAVA的世界中，maven已经成为事实上的构建标准，很多开源库的管理构建也是基于maven的，maven本身的学习曲线比较陡峭，遵循“约定优于配置”的理念，maven存在很多约定。本次我先描述下，关于版本的定义的选择，SNAPSHOT or RELEASE？  </p>
<ul>
<li>版本之争<br>在maven的约定中，依赖的版本分为两类——SNAPSHOT和RELEASE。SNAPSHOT依赖泛指以-SNAPSHOT为结尾的版本号，例如1.0.1-SNAPSHOT。除此之外，所有非-SNAPSHOT结尾的版本号则都被认定为RELEASE版本，即正式版，虽然会有beta、rc之类说法，但是这些只是软件工程角度的测试版，对于maven而言，这些都是RELEASE版本。既然Maven提供了这两类版本号，那么他们之前的优劣势是什么？分别在什么场景下使用？  </li>
<li>解读SNAPSHOT<br>同一个SNAPSHOT版本的依赖可以多次发布（deploy）到仓库中，也就是说同一个SNAPSHOT版本的依赖可以在仓库中存在多份，每一份都是代码在某一个特定时间的快照，这也是SNAPSHOT的含义。  </li>
<li>snapshot<br>如上图，很好地表达了SNAPSHOT的细节，也阐述了一个SNAPSHOT很重要观点——SNAPSHOT不是一个特定的版本，而是一系列的版本的集合，其中HEAD总是指向最新的快照，对外界可见的一般也是最新版，这种给人的假象是新的覆盖了老的，从而使得使用SNAPSHOT依赖的客户端总是通过重新构建（有时候需要-U强制更新）就可以拿到最新的代码。例如：A–&gt;B-1.3.8-SNAPSHOT（理解为A依赖了B的1.3.8-SNAPSHOT版本），那么B-1.3.8-SNAPSHOT更新之后重新deploy到仓库之后，A只需要重新构建就可以拿到最新的代码，并不需要改变依赖B的版本。由此可见，这样达到了变更传达的透明性，这对于开发过程中的团队协作的帮助不言而喻。  </li>
<li>SNAPSHOT之殇<br>SNAPSHOT版本的依赖因为存在变更传达的透明性的优势而被赏识，甚至被“溺爱”，有很多团队索性直接使用SNAPSHOT到生产环境中，这样对于变更直接生效，很方便。但是作为技术人员的我们其实应该很严谨地看待变更传达的透明性，变更就意味着风险，透明性更是把风险彻底隐藏了起来，生产环境中存在这样的现象更是心惊胆战。例如：A–&gt;B.1.0.3-SNAPSHOT，B对一个A使用的功能实现进行了调整，直接发布到仓库，A重新构建或许就会失败，更糟糕的是构建成功，运行时异常。这个时候A甚至完全没有代码变更就突然失败了，会带来更多的困惑。<br>这也是maven经常遭人诟病的一个因素，对于同一份代码，构建结果却不具备确定性，让很多人沮丧。当然这个不完全是因为依赖的问题，也有maven插件的问题，maven之前的版本寻找插件策略的方式也存在不确定性，maven在版本2的时候，会去寻找最新的插件版本（如果没配置的话）来执行构建，经常会找到SNAPSHOT版本的插件，所以依赖了一个不稳定的插件来执行构建，不确定性就大大增加。不过maven在3版本就改变了这个策略，会寻找最新稳定版的插件来执行构建，使得构建具备了确定性，稳定性也好多了。说明maven本身也在SNAPSHOT的问题上狠狠摔了一跤。<br>归根到底，这些问题的根源就是SNAPSHOT是变化的，是不稳定的，而应用（软件）依赖于变化并且不稳定的SNAPSHOT的依赖会导致自身也在变化和不稳定中，这是稳定性的一个大忌，依赖不稳定的服务或者依赖，上述的maven2的问题就是一个典型反例。  </li>
<li>RELEASE简介<br>RELEASE版本和SNAPSHOT是相对的，非SANPSHOT版本即RELEASE版本，RELEASE版本是一个稳定的版本号，看清楚咯，是一个，不是一系列，可以认为RELEASE版本是不可变化的，一旦发布，即永远不会变化。<br>虽然RELEASE版本是稳定不变的，但是仓库还是有策略让这个原则变得可配置，有的仓库会配置成redeploy覆盖，这样RELEASE版本就变成SNAPSHOT了，伪装成RELEASE的SNAPSHOT，会让问题更费解和棘手。<br>记住，RELEASE一旦发布，就不可改变。  </li>
<li>如何选择<br>那么什么时候使用SNAPSHOT？什么时候使用RELEASE?这个可以从他们各自的特性上来看，SNAPSHOT版本的库是一直在变化的，或者说随时都会变化的，这样虽然可以获取到最新的特性，但是也存在不稳定因素，依赖一个不稳定的模块或者库会让模块自身也变得不稳定，尤其是自身对被依赖模块的变化超出掌控的情况。即使可以掌控被依赖模块的变化，也会带来不稳定的因素，因为每次变更都有引入bug的可能性。如果这么说，那么我们是不是要摒弃SANPSHOT了呢？答案肯定是否定的。<br>想象下，什么情况下，模块会一直变化或者变化比较剧烈？开发新特性的时候，所以对于团队之间协同开发的时候，模块之间出现依赖，变化会非常剧烈，如模块A依赖模块B，模块A必然需要最方便地获取模块B的特性，在开发期间，方便性比稳定性更重要。可以反证下，假设模块B使用RELEASE版本1.0.0，模块A依赖1.0.0，现在模块A出现了bug，需要修复下，那么A就要提供一个版本号1.0.1，这样所有依赖A模块都需要更新版本号，因为开发期间这种事情是如此多，所以会带来巨变。反观SNAPSHOT方案，如果模块B的版本是1.0.0-SNAPSHOT，模块A完全不需要修改版本号即可获取模块B的新特性。当开发进入预发布阶段，为了生产环境的稳定性，依赖应该是RELEASE版本，因为此时SNAPSHOT版本的模块自动获取新特性的特点恰恰会造成生产环境的不稳定性，生产环境上，稳定性重于一切。  </li>
<li>魔幻之手<br>现在已经很明确了，在开发期间，活跃模块的版本号使用SNAPSHOT，在生产期间，依赖RELEASE版本模块。貌似，我们找到了银弹，不过这个只是理想状态，即所有的模块的版本都在自己的掌控或者间接掌控下，只有这样你才能影响对应模块的版本号。往往是理想很丰满，现实却很骨感，如果你依赖的一个模块只有SNAPSHOT版本，并且该模块也很活跃，最无助的是模块的维护人不理会你的请求，那么是否就没辙了，只能把应用构建在不稳定模块上呢？介绍一款maven插件——versions，这是一个非常强大的版本管理插件，其中有个对依赖版本加锁的特性——lock-snapshots，并且提供了参数可以控制锁定的依赖，就可以实现对特定的SNAPSHOT模块锁定版本，执行的命令如下：mvn versions:lock-snapshots -DincludesList=”groupId:artifactId:type:classifier:version”，执行这个命令之后，对应的版本号会变化，比如1.0.0-SNAPSHOT会变成1.0.0.20090327.172306-4，即完成了锁定，此时这个SNAPSHOT就变成了固定小版本的稳定版本，不会在变化了，也相当于正式版的功能了。当然以后也可以解锁，详细请看对应文档。  </li>
</ul>
<blockquote>
<p>摘自： <a href="https://www.cnblogs.com/wuchanming/p/5484091.html" target="_blank" rel="noopener">https://www.cnblogs.com/wuchanming/p/5484091.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>basics</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title>GitHub</title>
    <url>/2018/12/11/basics/github_basics/</url>
    <content><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
      <categories>
        <category>basics</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>WEB前端</title>
    <url>/2018/07/19/basics/web/</url>
    <content><![CDATA[<h2 id="前端基础知识"><a href="#前端基础知识" class="headerlink" title="前端基础知识"></a>前端基础知识</h2><ol>
<li><p><b>var</b>：<br>可以重复声明，如：var a = 5；var a = 12;<br>无法限制修改，<br>没有块级作用域<br>{ }即为块，例如：<br></br>if(true) {<br>var a = 5<br>}<br>console.log(a)</p>
<p><b>let</b>：<br>不能重复声明，<br>变量-可以修改，<br>有块级作用域<br><b>const</b>：<br>不能重复声明，<br>常量-不能修改，<br>有块级作用域</p>
</li>
</ol>
]]></content>
      <categories>
        <category>前端基础</category>
      </categories>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title>线上排查OOM</title>
    <url>/2019/05/15/basics/oom/</url>
    <content><![CDATA[<p>根据进程名称获取pid：ps -ef | grep “name” | grep -v grep | awk ‘{print $2}’</p>
<h4 id="OOM-排查"><a href="#OOM-排查" class="headerlink" title="OOM 排查"></a>OOM 排查</h4><h5 id="最常见的原因："><a href="#最常见的原因：" class="headerlink" title="最常见的原因："></a>最常见的原因：</h5><ul>
<li>有可能是内存分配确实过小，而正常业务使用了大量内存</li>
<li>某一个对象被频繁申请，却没有释放，内存不断泄漏，导致内存耗尽</li>
<li>某一个资源被频繁申请，系统资源耗尽，例如：不断创建线程，不断发起网络连接</li>
</ul>
<h5 id="一、确认是不是内存本身就分配过小"><a href="#一、确认是不是内存本身就分配过小" class="headerlink" title="一、确认是不是内存本身就分配过小"></a>一、确认是不是内存本身就分配过小</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jmap -heap PID</span><br></pre></td></tr></table></figure>
<h5 id="二、找到最耗内存的对象"><a href="#二、找到最耗内存的对象" class="headerlink" title="二、找到最耗内存的对象"></a>二、找到最耗内存的对象</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jmap -histo PID | head -10</span><br></pre></td></tr></table></figure>
<h5 id="三、确认是否是资源耗尽"><a href="#三、确认是否是资源耗尽" class="headerlink" title="三、确认是否是资源耗尽"></a>三、确认是否是资源耗尽</h5><p>查看进程创建的线程数，以及网络连接数，如果资源耗尽，也可能出现OOM。</p>
<ul>
<li>/proc/${PID}/fd | wc -l</li>
<li>/proc/${PID}/task | wc -l （效果等同pstree -p | wc -l）<br>查看进程打开的句柄数和线程数。</li>
</ul>
<h5 id="线上服务CPU100-问题快速定位"><a href="#线上服务CPU100-问题快速定位" class="headerlink" title="线上服务CPU100%问题快速定位"></a>线上服务CPU100%问题快速定位</h5><h6 id="一、找到最耗CPU的进程"><a href="#一、找到最耗CPU的进程" class="headerlink" title="一、找到最耗CPU的进程"></a>一、找到最耗CPU的进程</h6><ul>
<li>执行top -c ，显示进程运行信息列表</li>
<li>键入P (大写p)，进程按照CPU使用率排序</li>
</ul>
<h5 id="二、找到最耗CPU的线程"><a href="#二、找到最耗CPU的线程" class="headerlink" title="二、找到最耗CPU的线程"></a>二、找到最耗CPU的线程</h5><ul>
<li>top -Hp PID ，显示一个进程的线程运行信息列表</li>
<li>键入P (大写p)，线程按照CPU使用率排序</li>
</ul>
<h5 id="三、将线程PID转化为16进制"><a href="#三、将线程PID转化为16进制" class="headerlink" title="三、将线程PID转化为16进制"></a>三、将线程PID转化为16进制</h5><ul>
<li>printf “%x\n” TID</li>
</ul>
<h5 id="四、查看堆栈，找到线程在干嘛"><a href="#四、查看堆栈，找到线程在干嘛" class="headerlink" title="四、查看堆栈，找到线程在干嘛"></a>四、查看堆栈，找到线程在干嘛</h5><p>jstack PID | grep ‘0xXXX’ -C5 –color</p>
]]></content>
      <categories>
        <category>basics</category>
      </categories>
      <tags>
        <tag>oom</tag>
      </tags>
  </entry>
  <entry>
    <title>Mybatis的缓存机制及其作用的原理</title>
    <url>/2019/09/26/database/mybatis/</url>
    <content><![CDATA[<h3 id="Mybatis缓存机制"><a href="#Mybatis缓存机制" class="headerlink" title="Mybatis缓存机制"></a>Mybatis缓存机制</h3><p>mybatis提供了缓存机制减轻数据库压力，提高数据库性能<br>mybatis的缓存分为两级：一级缓存、二级缓存<br>一级缓存是SqlSession级别的缓存，缓存的数据只在SqlSession内有效<br>二级缓存是mapper级别的缓存，同一个namespace公用这一个缓存，所以对SqlSession是共享的  </p>
<h4 id="一级缓存"><a href="#一级缓存" class="headerlink" title="一级缓存"></a>一级缓存</h4><p>mybatis的一级缓存是SqlSession级别的缓存，在操作数据库的时候需要先创建SqlSession会话对象，在对象中有一个HashMap用于存储缓存数据，此HashMap是当前会话对象私有的，别的SqlSession会话对象无法访问。<br>当一个sqlSession结束后该sqlSession中的一级缓存也就不存在了。(PerpetualCache) </p>
<ul>
<li>具体流程：</li>
</ul>
<ol>
<li>第一次执行select完毕会将查到的数据写入SqlSession内的HashMap中缓存起来</li>
<li>第二次执行select会从缓存中查数据，如果select相同切传参数一样，那么就能从缓存中返回数据，不用去数据库了，从而提高了效率</li>
</ol>
<ul>
<li>注意：</li>
</ul>
<ol>
<li>如果SqlSession执行了DML操作（insert、update、delete），并commit了，那么mybatis就会清空当前SqlSession缓存中的所有缓存数据，这样可以保证缓存中的存的数据永远和数据库中一致，避免出现脏读</li>
<li>当一个SqlSession结束后那么他里面的一级缓存也就不存在了，mybatis默认是开启一级缓存，不需要配置</li>
<li>mybatis的缓存是基于[namespace:sql语句:参数]来进行缓存的，意思就是，SqlSession的HashMap存储缓存数据时，是使用[namespace:sql:参数]作为key，查询返回的语句作为value保存的。例如：-1242243203:1146242777:winclpt.bean.userMapper.getUser:0:2147483647:select * from user where id=?:19</li>
</ol>
<h4 id="二级缓存"><a href="#二级缓存" class="headerlink" title="二级缓存"></a>二级缓存</h4><p>二级缓存是mapper级别的缓存，也就是同一个namespace的mappe.xml，当多个SqlSession使用同一个Mapper操作数据库的时候，得到的数据会缓存在同一个二级缓存区域<br>二级缓存它有数据的多session共享机制，但是呢，会导致user在两个命名空间下的数据不一致。<br>二级缓存默认是没有开启的。需要在setting全局参数中配置开启二级缓存。</p>
<ol>
<li>conf.xml：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;settings&gt;</span><br><span class="line">        &lt;setting name&#x3D;&quot;cacheEnabled&quot; value&#x3D;&quot;true&quot;&#x2F;&gt;默认是false：关闭二级缓存</span><br><span class="line">&lt;settings&gt;</span><br></pre></td></tr></table></figure></li>
<li>mapper.xml<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;cache eviction&#x3D;&quot;LRU&quot; flushInterval&#x3D;&quot;60000&quot; size&#x3D;&quot;512&quot; readOnly&#x3D;&quot;true&quot;&#x2F;&gt;当前mapper下所有语句开启二级缓存</span><br></pre></td></tr></table></figure>
这里配置了一个LRU缓存，并每隔60秒刷新，最大存储512个对象，而却返回的对象是只读的<br>若想禁用当前select语句的二级缓存，添加useCache=”false”修改如下：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;select id&#x3D;&quot;getCountByName&quot; parameterType&#x3D;&quot;java.util.Map&quot; resultType&#x3D;&quot;INTEGER&quot; statementType&#x3D;&quot;CALLABLE&quot; useCache&#x3D;&quot;false&quot;&gt;</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>具体流程：  </li>
</ul>
<ol>
<li>当一个sqlseesion执行了一次select后，在关闭此session的时候，会将查询结果缓存到二级缓存  </li>
<li>当另一个sqlsession执行select时，首先会在他自己的一级缓存中找，如果没找到，就回去二级缓存中找，找到了就返回，就不用去数据库了，从而减少了数据库压力提高了性能  </li>
</ol>
<blockquote>
<p>学习：<a href="https://www.cnblogs.com/winclpt/articles/7511672.html" target="_blank" rel="noopener">https://www.cnblogs.com/winclpt/articles/7511672.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSql</title>
    <url>/2018/12/21/database/postgresql/</url>
    <content><![CDATA[<h3 id="psql常用命令"><a href="#psql常用命令" class="headerlink" title="psql常用命令"></a>psql常用命令</h3><h5 id="连接数据库"><a href="#连接数据库" class="headerlink" title="连接数据库"></a>连接数据库</h5><p>psql -h [ip] -U [username] -d [databases]</p>
<ul>
<li>创建schema<br>CREATE SCHEMA my_schema;<br>GRANT ALL ON SCHEMA my_schema TO my_user;</li>
<li>查看当前schema<br>SHOW search_path;</li>
<li>查询数据库下所有schema<br>select * from information_schema.schemata;</li>
<li>查询指定schema下所有表<br>select * from information_schema.tables where table_schema=’audit’;</li>
<li>切换schema（连接级）<br>set search_path to my_schema;</li>
<li>改变默认schema（数据库级）<br>ALTER database “my_database” SET search_path TO my_schema;</li>
<li>指定schema查询<br>select count(*) from audit.fxk_pg_oplog;</li>
</ul>
<h3 id="pg基础知识与基本操作"><a href="#pg基础知识与基本操作" class="headerlink" title="pg基础知识与基本操作"></a>pg基础知识与基本操作</h3><p><span style="color:red">查询pg库的所有表名称</span><br>select tablename from pg_tables where schemaname=’public’;<br><span style="color:red">获取pg表的字段</span><br>select column_name from information_schema.columns<br>where table_name = ‘db_job’;</p>
<p><span style="color:red">–查看当前活动的客户端连接数</span><br> SELECT count(*) FROM pg_stat_activity WHERE NOT pid=pg_backend_pid();<br><span style="color:red">–查看PostgreSQL正在执行的SQL</span><br>SELECT<br>    procpid,<br>    start,<br>    now() - start AS lap,<br>    current_query<br>FROM<br>    (SELECT<br>        backendid,<br>        pg_stat_get_backend_pid(S.backendid) AS procpid,<br>        pg_stat_get_backend_activity_start(S.backendid) AS start,<br>       pg_stat_get_backend_activity(S.backendid) AS current_query<br>    FROM<br>        (SELECT pg_stat_get_backend_idset() AS backendid) AS S<br>    ) AS S ,pg_stat_activity pa<br>WHERE<br>   current_query &lt;&gt; ‘<IDLE>‘ and  procpid&lt;&gt; pg_backend_pid() and pa.pid=s.procpid and pa.state&lt;&gt;’idle’<br>ORDER BY<br>   lap DESC;<br><span style="color:red">–查看当前库表和索引的的大小并排序显示前20条</span><br>SELECT<br>nspname,<br>relname,<br>relkind as “type”,<br>pg_size_pretty(pg_table_size(C.oid)) AS size,<br>pg_size_pretty(pg_indexes_size(C.oid)) AS idxsize,<br>pg_size_pretty(pg_total_relation_size(C.oid)) as “total”<br>FROM pg_class C<br>LEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)<br>WHERE nspname NOT IN (‘pg_catalog’, ‘information_schema’) AND<br>nspname !~ ‘^pg_toast’ AND<br>relkind IN (‘r’,’i’)<br>ORDER BY pg_total_relation_size(C.oid) DESC<br>LIMIT 20; </p>
<span style="color:blue">
procpid：进程id  
start：进程开始时间  
lap：经过时间  
current_query：执行中的sql  
怎样停止正在执行的sql  
SELECT pg_cancel_backend(进程id);  
或者用系统函数  
kill -9 进程id;
--查找是否有waiting  
ps -ef|grep postgres | grep wait
</span>

<p>排序：ORDER BY 字段 DESC<br><span style="color:red">模糊不区分大小写查询：</span>UPPER(字段) LIKE UPPER(‘%${search}%’)<br><span style="color:red">查指定条数：</span>LIMIT 长度 OFFSET 起始位置</p>
<p>关联查询：<br>SELECT fail_count<br>FROM test_report AS  f<br>INNER JOIN(SELECT MAX(id) AS b_id FROM test_build WHERE job_id = #{jobId})  r<br>ON f.build_id = r.b_id</p>
<p><span style="color:red">去重返回</span><br>SELECT <span style="color:red">DISTINCT</span><br>    T.parent_id<br>FROM<br>    db_task AS T<br>INNER JOIN db_job AS j ON T.status IN (<br>    ‘running’,<br>    ‘initComplete’,<br>    ‘fail’<br>)<br>AND j.status IN (‘created’, ‘dispatched’)</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>pg</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker</title>
    <url>/2019/01/14/basics/docker_basics/</url>
    <content><![CDATA[<h3 id="Docker简介"><a href="#Docker简介" class="headerlink" title="Docker简介"></a>Docker简介</h3><p>Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。<br>Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。<br>容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低</p>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>Web 应用的自动化打包和发布。</p>
<p>自动化测试和持续集成、发布。</p>
<p>在服务型环境中部署和调整数据库或其他的后台应用。</p>
<p>从头编译或者扩展现有的OpenShift或Cloud Foundry平台来搭建自己的PaaS环境。</p>
]]></content>
      <categories>
        <category>basics</category>
      </categories>
      <tags>
        <tag>docker order</tag>
      </tags>
  </entry>
  <entry>
    <title>cron基础用法</title>
    <url>/2018/07/20/java/cron_java/</url>
    <content><![CDATA[<p>在线Cron表达式生成器 : <a href="http://cron.qqe2.com/" target="_blank" rel="noopener">http://cron.qqe2.com/</a></p>
<p>（1）<span style="color:red">*</span>：表示匹配该域的任意值。假如在Minutes域使用<em>, 即表示每分钟都会触发事件。<br>（2）<span style="color:red">?</span>：只能用在DayofMonth和DayofWeek两个域。它也匹配域的任意值，但实际不会。因为DayofMonth和DayofWeek会相互影响。例如想在每月的20日触发调度，不管20日到底是星期几，则只能使用如下写法： 13 13 15 20 * ?, 其中最后一位只能用？，而不能使用</em>，如果使用*表示不管星期几都会触发，实际上并不是这样。<br>（3）<span style="color:red">-</span>：表示范围。例如在Minutes域使用5-20，表示从5分到20分钟每分钟触发一次<br>（4）<span style="color:red">/</span>：表示起始时间开始触发，然后每隔固定时间触发一次。例如在Minutes域使用5/20,则意味着5分钟触发一次，而25，45等分别触发一次.<br>（5）<span style="color:red">,</span>：表示列出枚举值。例如：在Minutes域使用5,20，则意味着在5和20分每分钟触发一次。<br>（6）<span style="color:red">L</span>：表示最后，只能出现在DayofWeek和DayofMonth域。如果在DayofWeek域使用5L,意味着在最后的一个星期四触发。<br>（7）<span style="color:red">W</span>:表示有效工作日(周一到周五),只能出现在DayofMonth域，系统将在离指定日期的最近的有效工作日触发事件。例如：在 DayofMonth使用5W，如果5日是星期六，则将在最近的工作日：星期五，即4日触发。如果5日是星期天，则在6日(周一)触发；如果5日在星期一到星期五中的一天，则就在5日触发。另外一点，W的最近寻找不会跨过月份 。<br>（8）<span style="color:red">LW</span>:这两个字符可以连用，表示在某个月最后一个工作日，即最后一个星期五。<br>（9）<span style="color:red">#</span> :用于确定每个月第几个星期几，只能出现在DayofMonth域。例如在4#2，表示某月的第二个星期三。</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>cron</tag>
      </tags>
  </entry>
  <entry>
    <title>TIME_WAIT状态分析</title>
    <url>/2019/07/31/http/time_wait/</url>
    <content><![CDATA[<h3 id="TCP三次握手四次挥手"><a href="#TCP三次握手四次挥手" class="headerlink" title="TCP三次握手四次挥手"></a>TCP三次握手四次挥手</h3><h4 id="三次握手-（建立连接协议）"><a href="#三次握手-（建立连接协议）" class="headerlink" title="三次握手 （建立连接协议）"></a>三次握手 （建立连接协议）</h4><ul>
<li>第一次握手：建立连接时，客户端发送syn包（syn=j）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。</li>
<li>第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态。</li>
<li>第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。  <blockquote>
<p>握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP连接都将被一直保持下去。  </p>
</blockquote>
</li>
</ul>
<h4 id="四次挥手（连接终止协议）"><a href="#四次挥手（连接终止协议）" class="headerlink" title="四次挥手（连接终止协议）"></a>四次挥手（连接终止协议）</h4><ul>
<li>第一次挥手：主动关闭方发送一个FIN，用来关闭主动方到被动关闭方的数据传送，也就是主动关闭方告诉被动关闭方：我已经不会再给你发数据了(当然，在fin包之前发送出去的数据，如果没有收到对应的ack确认报文，主动关闭方依然会重发这些数据)，但是，此时主动关闭方还可以接受数据。主动方处于FIN_WAIT_1状态</li>
<li>第二次挥手：被动关闭方收到FIN包后，发送一个ACK给对方，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号， SYN 和 FIN 都有seq序号）。主动方处于FIN_WAIT_2状态</li>
<li>第三次挥手：被动关闭方发送一个FIN，用来关闭被动关闭方到主动关闭方的数据传送，也就是告诉主动关闭方，我的数据也发送完了，不会再给你发数据了。被动房处于LAST_ACK状态</li>
<li>第四次挥手：主动关闭方收到FIN后，发送一个ACK给被动关闭方，主动方此时处于TIME_WAIT状态，被动方收到ACK报文后关闭连接，至此，完成四次挥手。  <blockquote>
<p>由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。</p>
</blockquote>
</li>
</ul>
<h4 id="状态解释"><a href="#状态解释" class="headerlink" title="状态解释"></a>状态解释</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CLOSED：无连接是活动的或正在进行</span><br><span class="line">LISTEN：服务器在等待进入呼叫</span><br><span class="line">SYN_RECV：一个连接请求已经到达，等待确认</span><br><span class="line">SYN_SENT：应用已经开始，打开一个连接</span><br><span class="line">ESTABLISHED：正常数据传输状态</span><br><span class="line">FIN_WAIT1：应用说它已经完成</span><br><span class="line">FIN_WAIT2：另一边已同意释放</span><br><span class="line">ITMED_WAIT：等待所有分组死掉</span><br><span class="line">CLOSING：两边同时尝试关闭</span><br><span class="line">TIME_WAIT：另一边已初始化一个释放</span><br><span class="line">LAST_ACK：等待所有分组死掉</span><br></pre></td></tr></table></figure>

<h4 id="TIME-WAIT过多问题原因及解决（Cannot-assign-requested-address）"><a href="#TIME-WAIT过多问题原因及解决（Cannot-assign-requested-address）" class="headerlink" title="TIME_WAIT过多问题原因及解决（Cannot assign requested address）"></a>TIME_WAIT过多问题原因及解决（Cannot assign requested address）</h4><ul>
<li><p>什么时候会出现TIME_WAIT<br>TCP在关闭的时候有个四次挥手的过程，主动关闭方在四次挥手的最后一个ACK发送之后会变成TIME_WAIT状态。</p>
</li>
<li><p>TIME_WAIT状态维持多久<br>主动关闭方响应完最后一次ACK之后，会在TIME_WAIT这个状态维持2MSL</p>
</li>
<li><p>MSL<br>MSL全称是maximum segment lifetime，最长分节生命期。MSL是任何IP数据报能够在因特网存活的最长时间。我们知道，这个时间是有限的，因为每个数据报都含有一个限跳（hop limit）的8位字段，它的最大值是255（简单的讲就是不同经过超过255个路由器）。尽管这个跳数限制而不是真正的时间限制，我们仍然假设最大限跳的分组在网络中存在的时间不可能超过MSL秒。</p>
</li>
<li><p>TIME_WAIT的作用<br>1）可靠地实现TCP全双工连接的终止<br> 在进行关闭连接四次挥手协议时，最后的ACK是由主动关闭端发出的，如果这个最终的ACK丢失，服务器将重发最终的FIN，<br>因此客户端必须维护状态信息允许它重发最终的ACK。如果不维持这个状态信息，那么客户端将响应RST分节，服务器将此分节解释成一个错误（在java中会抛出connection reset的SocketException)。<br>因而，要实现TCP全双工连接的正常终止，必须处理终止序列四个分节中任何一个分节的丢失情况，主动关闭的客户端必须维持状态信息进入TIME_WAIT状态。<br>2）允许老的重复分节在网络中消逝<br>TCP分节可能由于路由器异常而“迷途”，在迷途期间，TCP发送端可能因确认超时而重发这个分节，迷途的分节在路由器修复后也会被送到最终目的地，这个原来的迷途分节就称为lost duplicate。<br>在关闭一个TCP连接后，马上又重新建立起一个相同的IP地址和端口之间的TCP连接，后一个连接被称为前一个连接的化身（incarnation)，那么有可能出现这种情况，前一个连接的迷途重复分组在前一个连接终止后出现，从而被误解成从属于新的化身。<br>为了避免这个情况，TCP不允许处于TIME_WAIT状态的连接启动一个新的化身，因为TIME_WAIT状态持续2MSL，就可以保证当成功建立一个TCP连接的时候，来自连接先前化身的重复分组已经在网络中消逝。  </p>
</li>
<li><p>大量TIME_WAIT造成的影响<br>在高并发短连接的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接。这个场景下会出现大量socket处于TIME_WAIT状态。如果客户端的并发量持续很高，此时部分客户端就会显示连接不上。<br>主动正常关闭TCP连接，都会出现TIMEWAIT。<br>为什么我们要关注这个高并发短连接呢？有两个方面需要注意：</p>
</li>
</ul>
<ol>
<li>高并发可以让主动方（大部分是客户端）在短时间范围内同时占用大量端口，而端口有个0~65535的范围，并不是很多，刨除系统和其他服务要用的，剩下的就更少了。（服务端端口是复用的）</li>
<li>在这个场景中，短连接表示“业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间”的连接。<br>例如： 取一个web页面，1秒钟的http短连接处理完业务，在关闭连接之后，这个业务用过的端口会停留在TIMEWAIT状态几分钟，而这几分钟，其他HTTP请求来临的时候是无法占用此端口的(占着茅坑不拉翔)。单用这个业务计算服务器的利用率会发现，服务器干正经事的时间和端口（资源）被挂着无法被使用的时间的比例是 1：几百，服务器资源严重浪费。（说个题外话，从这个意义出发来考虑服务器性能调优的话，长连接业务的服务就不需要考虑TIMEWAIT状态。同时，假如你对服务器业务场景非常熟悉，你会发现，在实际业务场景中，一般长连接对应的业务的并发量并不会很高。  </li>
</ol>
]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>time_wait</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis</title>
    <url>/2019/07/19/database/redis/</url>
    <content><![CDATA[<h3 id="Redis命令"><a href="#Redis命令" class="headerlink" title="Redis命令"></a>Redis命令</h3><ul>
<li>连接  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">redis-cli -h host -p post -a pwd</span><br></pre></td></tr></table></figure>
<h4 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h4></li>
<li>info – 查看信息</li>
<li>select [num] – 选择index</li>
<li>keys * – 查看所有key</li>
<li>SET key value – 设置指定 key 的值</li>
<li>GET key – 获取指定 key 的值</li>
<li>GETSET key value – 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。</li>
<li>MGET key1 [key2..] – 获取所有(一个或多个)给定 key 的值。</li>
<li>SETEX key seconds value – 将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)。</li>
<li>PSETEX key milliseconds value – 以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位。</li>
<li>SETNX key value – 只有在 key 不存在时设置 key 的值。</li>
<li>MSET key value [key value …] – 同时设置一个或多个 key-value 对。</li>
<li>APPEND key value – 如果 key 已经存在并且是一个字符串， APPEND 命令将指定的 value 追加到该 key 原来值（value）的末尾。  </li>
<li>DEL key – 该命令用于在 key 存在时删除 key。</li>
<li>EXISTS key – 检查给定 key 是否存在。</li>
<li>DUMP key – 序列化给定 key ，并返回被序列化的值</li>
<li>PERSIST key – 移除 key 的过期时间，key 将持久保持。</li>
<li>PTTL key – 以毫秒为单位返回 key 的剩余的过期时间</li>
<li>RANDOMKEY – 从当前数据库中随机返回一个 key</li>
<li>RENAME key newkey – 修改 key 的名称</li>
<li>RENAMENX key newkey – 仅当 newkey 不存在时，将 key 改名为 newkey</li>
<li>TYPE key – 返回 key 所储存的值的类型</li>
</ul>
<h4 id="pub-发布-sub-订阅"><a href="#pub-发布-sub-订阅" class="headerlink" title="pub(发布) - sub(订阅)"></a>pub(发布) - sub(订阅)</h4><p>Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。<br>Redis 客户端可以订阅任意数量的频道  </p>
<h4 id="列表（List）"><a href="#列表（List）" class="headerlink" title="列表（List）"></a>列表（List）</h4><ul>
<li>LLEN key  获取列表长度</li>
<li>LPOP key  移除并获取列表第一个元素</li>
<li>RPOP key  移除并获取列表最后一个元素</li>
<li>LREM key count value  移除列表元素</li>
<li>RPUSHX key value  对已存在的列表添加元素</li>
<li>LPUSHX key value  将元素插入已存在列表头部</li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>HashMap原理</title>
    <url>/2019/09/26/java/hash_map/</url>
    <content><![CDATA[<h3 id="HashMap的工作原理"><a href="#HashMap的工作原理" class="headerlink" title="HashMap的工作原理"></a>HashMap的工作原理</h3><ul>
<li>HashMap的工作原理？（基于hashing，bucket中存储键值对）<br>HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，让后找到bucket位置来储存值对象。当获取对象时，通过键对象的equals()方法找到正确的键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。</li>
<li>当两个对象的hashCode相同会发生什么？（hashCode()和equals()方法）<br>它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。<br>注：首先，hashCode相同，但equals不一定相等，因为hashcode相同，所以它们的bucket位置相同，‘碰撞’会发生。因为HashMap使用链表存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在链表中。</li>
<li>如果两个键的hashcode相同，如何获取值对象？（HashMap在链表中存储的是键值对）<br>当我们调用get()方法，HashMap会使用键对象的hashcode找到bucket位置，找到bucket位置之后，会调用keys.equals()方法去找到链表中正确的节点。<br>使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生，提高效率。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择。</li>
<li>如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？（HashMap负载因子0.75）<br>默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。</li>
<li>重新调整HashMap大小存在什么问题吗？（多线程的情况下，可能产生条件竞争(race condition)）<br>如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了。（多线程不适用HashMap）</li>
<li>为什么String, Interger这样的wrapper类适合作为键<br>String最为常用。因为String是不可变的，也是final的，而且已经重写了equals()和hashCode()方法了。其他的wrapper类也有这个特点。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。不可变性还有其他的优点如线程安全。</li>
<li>我们可以使用CocurrentHashMap来代替Hashtable吗？（Hashtable是synchronized的）<br>ConcurrentHashMap同步性能更好，因为它仅仅根据同步级别对map的一部分进行上锁。ConcurrentHashMap当然可以代替HashTable，但是HashTable提供更强的线程安全性。</li>
</ul>
<h3 id="HashCode与equals"><a href="#HashCode与equals" class="headerlink" title="HashCode与equals"></a>HashCode与equals</h3><ul>
<li>就是hashCode是用于查找使用的，而equals是用于比较两个对象的是否相等的<h4 id="HashCode"><a href="#HashCode" class="headerlink" title="HashCode"></a>HashCode</h4></li>
</ul>
<ol>
<li>shCode的存在主要是用于查找的快捷性，如Hashtable，HashMap等，hashCode是用来在散列存储结构中确定对象的存储地址的</li>
<li>如果两个对象相同，就是适用于equals(java.lang.Object) 方法，那么这两个对象的hashCode一定要相同。</li>
<li>如果对象的equals方法被重写，那么对象的hashCode也尽量重写，并且产生hashCode使用的对象，一定要和equals方法中使用的一致，否则就会违反上面提到的第2点。</li>
<li>两个对象的hashCode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object) 方法，只能够说明这两个对象在散列存储结构中，如Hashtable，他们“存放在同一个篮子里“。<h4 id="Equals"><a href="#Equals" class="headerlink" title="Equals"></a>Equals</h4></li>
<li>equals和==<br>==用于比较引用和比较基本数据类型时具有不同的功能：<br>比较基本数据类型，如果两个值相同，则结果为true<br>而在比较引用时，如果引用指向内存中的同一对象，结果为true;<br>equals()作为方法，实现对象的比较。由于==运算符不允许我们进行覆盖，也就是说它限制了我们的表达。因此我们复写equals()方法，达到比较对象内容是否相同的目的。而这些通过==运算符是做不到的。</li>
<li>object类的equals()方法的比较规则为：<br>如果两个对象的类型一致，并且内容一致，则返回true,这些类有：<br>java.io.file,java.util.Date,java.lang.string,包装类（Integer,Double等）<br>String s1=new String(“abc”);<br>String s2=new String(“abc”);<br>System.out.println(s1==s2);<br>System.out.println(s1.equals(s2));<br>运行结果为false true  </li>
</ol>
<h4 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h4><p> HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。<br> 在java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。  </p>
<h4 id="HashMap的存取"><a href="#HashMap的存取" class="headerlink" title="HashMap的存取"></a>HashMap的存取</h4><p>根据hash值得到这个元素在数组中的位置（即下标），如果数组该位置上已经存放有其他元素了，那么在这个位置上的元素将以链表的形式存放，新加入的放在链头，最先加入的放在链尾。如果数组该位置上没有元素，就直接将该元素放到此数组中的该位置上。<br>hash(int h)方法根据key的hashCode重新计算一次散列。此算法加入了高位计算，防止低位不变，高位变化时，造成的hash冲突。  </p>
<ol>
<li>存储<br>当程序试图将一个key-value对放入HashMap中时，程序首先根据该 key的 hashCode() 返回值决定该 Entry 的存储位置：如果两个 Entry 的 key 的 hashCode() 返回值相同，那它们的存储位置相同。如果这两个 Entry 的 key 通过 equals 比较返回 true，新添加 Entry 的 value 将覆盖集合中原有 Entry的 value，但key不会覆盖。如果这两个 Entry 的 key 通过 equals 比较返回 false，新添加的 Entry 将与集合中原有 Entry 形成 Entry 链，而且新添加的 Entry 位于 Entry 链的头部——具体说明继续看 addEntry() 方法的说明。  </li>
<li>读取<br>从HashMap中get元素时，首先计算key的hashCode，找到数组中对应位置的某一元素，然后通过key的equals方法在对应位置的链表中找到需要的元素。  <ul>
<li>总结：HashMap 在底层将 key-value 当成一个整体进行处理，这个整体就是一个 Entry 对象。HashMap 底层采用一个 Entry[] 数组来保存所有的 key-value 对，当需要存储一个 Entry 对象时，会根据hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry  <h4 id="HashMap的resize"><a href="#HashMap的resize" class="headerlink" title="HashMap的resize"></a>HashMap的resize</h4>当hashmap中的元素越来越多的时候，碰撞的几率也就越来越高（因为数组的长度是固定的），所以为了提高查询的效率，就要对hashmap的数组进行扩容，数组扩容这个操作也会出现在ArrayList中，所以这是一个通用的操作，很多人对它的性能表示过怀疑，不过想想我们的“均摊”原理，就释然了，而在hashmap数组扩容之后，最消耗性能的点就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是resize。<br>那么hashmap什么时候进行扩容呢？当hashmap中的元素个数超过数组大小<em>loadFactor时，就会进行数组扩容，loadFactor的默认值为0.75，也就是说，默认情况下，数组大小为16，那么当hashmap中元素个数超过16</em>0.75=12的时候，就把数组的大小扩展为2<em>16=32，即扩大一倍，然后重新计算每个元素在数组中的位置，而这是一个非常消耗性能的操作，所以如果我们已经预知hashmap中元素的个数，那么预设元素的个数能够有效的提高hashmap的性能。比如说，我们有1000个元素new HashMap(1000), 但是理论上来讲new HashMap(1024)更合适，不过上面annegu已经说过，即使是1000，hashmap也自动会将其设置为1024。 但是new HashMap(1024)还不是更合适的，因为0.75</em>1000 &lt; 1000, 也就是说为了让0.75 * size &gt; 1000, 我们必须这样new HashMap(2048)才最合适，既考虑了&amp;的问题，也避免了resize的问题。</li>
</ul>
</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>HashMap的实现原理：<br>利用key的hashCode重新hash计算出当前对象的元素在数组中的下标<br>存储时，如果出现hash值相同的key，此时有两种情况。(1)如果key相同，则覆盖原始值；(2)如果key不同（出现冲突），则将当前的key-value放入链表中<br>获取时，直接找到hash值对应的下标，在进一步判断key是否相同，从而找到对应值。<br>理解了以上过程就不难明白HashMap是如何解决hash冲突的问题，核心就是使用了数组的存储方式，然后将冲突的key的对象放入链表中，一旦发现冲突就在链表中做进一步的对比。  </p>
<blockquote>
<p>借鉴：<a href="https://www.cnblogs.com/yuanblog/p/4441017.html" target="_blank" rel="noopener">https://www.cnblogs.com/yuanblog/p/4441017.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>hashMap</tag>
      </tags>
  </entry>
  <entry>
    <title>AOP(审计日志的开发与延伸)</title>
    <url>/2018/12/11/java/aop_audit_log_java/</url>
    <content><![CDATA[<h3 id="注解-Annotation"><a href="#注解-Annotation" class="headerlink" title="注解 Annotation"></a>注解 Annotation</h3><p>Annotation其实是代码里的特殊标记，这些标记可以在编译、类加载、运行时被读取，并执行相应的处理。通过使用Annotation，程序开发人员可以在不改变原有逻辑的情况下，在源文件嵌入一些补充信息。代码分析工具、开发工具和部署工具可以通过这些补充信息进行验证或者进行部署。<br></p>
<p>　　Annotation提供了一条为程序元素设置元数据的方法，从某些方面来看，Annotation就像修饰符一样被使用，可用于修饰包、类、构造器、方法、成员变量、参数、局部变量的声明，这些信息被存储在Annotation的“name=value”对中。<br></p>
<p>　　Annotation能被用来为程序元素(类、方法、成员变量等)设置元数据。值得指出的是：Annotation不能影响程序代码的执行，无论增加、删除Annotation，代码都始终如一地执行。如果希望让程序中的Annotation能在运行时起一定的作用，只有通过某种配套的工具对Annotation中的信息进行访问的处理，访问和处理Annotation的工具统称APT（Annotation Processing Tool） <br><br><br>Annotation必须使用工具来处理，工具负责提取Annotation里包含的元数据，工具还会根据这些元数据增加额外的功能。<br><br>三个基本的Annotation：<br><br>@Override         限定重写父类的方法<br><br>@Deprecated     标示已过时<br><br>@SuppressWarnings     抑制编译器警告<br></p>
<p><b>自定义Annotation</b><br>定义新的Annotation类型使用@interface关键字，它用于定义新的Annotation类型。定义一个新的Annotation类型与定义一个接口非常像<br><br>定义一个简单的注解：</p>
<pre>
public @interface GetLog {
}
</pre>
<p>带成员变量的Annotation，Annotation的成员变量在Annotation定义中以无参数方法的形式声明。其方法名和返回值定义了该成员的名字和类型<br><br>同时使用时也要指定相应的变量值</p>
<pre>
public @interface GetLog {
    //定义成员变量
    String name();
}

@GetLog(name = "log")
public void getName(){}
</pre>
<p>我们还可以在定义Annotation的成员变量时为其指定初始值，指定成员变量的初始值可使用default关键字;</p>
<pre>
public @interface GetLog {
    //定义成员变量
    String description() default "${description}";
}
</pre>

<p>根据我们介绍的Annotation是否可以包含成员变量，我们可以把Annotation分为如下两类：<br><br>标记Annotation： 一个没有成员定义的Annotation类型被称为标记。这种Annotation仅使用自身的存在与否来为我们提供信息。如前面介绍的@Override。<br><br>元数据Annotation：那些包含成员变量的Annotation，因为它们可接受更多元数据，所以也被称为元数据Annotation。<br></p>
<p><b>提取Annotation信息</b><br>Java使用Annotation接口来代表程序元素前面的注释（反射的时候用它来接收注解对象），该接口是所有Annotation类型的父接口;<br><br>Java在java.lang.reflect包下新增了AnnotateElement接口，该接口代表程序中可以接受注释的程序元素，该接口主要有如下几个实现类（注意以下是类: <br><br>Class：类定义。<br><br>Constructor：构造器定义。<br><br>Field：类的成员变量定义。<br><br>Method：类的方法定义。<br><br>Package：类的包定义。<br><br>java.lang.reflect包下主要包含一些实现反射功能工具类，实际上，java.lang.reflect包提供的反射API扩充了读取运行时Annotation的能力。当一个Annotation类型被定义为运行时Annotation后，该注解才是运行时可见，当class文件被装载时被保存在class文件中的Annotation才会被虚拟机读取。<br><br>AnnotatedElement接口是所有程序元素（如Class、Method、Constructor）的父接口，所以程序通过反射获取了某个类的AnnotatedElement对象（如Class、Method、Constructor）之后，程序就可以调用该对象的如下三个方法来访问Annotation信息：<br><br>getAnnotation(Class<T> annotationClass);  //返回该程序元素上存在的、指定类型的注释，如果该类型的注释不存在，则返回null。<br><br>Annotation[] getAnnotations();      //返回该程序元素上存在的所有注释。<br><br>boolean isAnnotationPresent(Class&lt;? extends Annotation&gt; annotationClass);      //判断该程序元素上是否包含指定类型的注解，存在则返回true，否则返回false。<br></p>
<pre>
//@Retention注解指定GetLog注解保留多久
@Retention(RetentionPolicy.RUNTIME)
//@Target注解指定注解能修饰的目标(只能是方法)
@Target(ElementType.METHOD)
public @interface GetLog {
    String description() default "${description}";
}
<pre>

定义Annotation时使用了<span style="color:red">@Retention</span>和<span style="color:red">@Target</span>两个系统元注释，其中@Retention注释指定Test注释可以保留多久，@Target注释指定Test注释能修饰的目标（）.<br>
仅仅使用注释来标识程序元素对程序是不会有任何影响的，这也是Java注释的一条重要原则。<br>
<span style="color:red">@Retention</span>
@Retention只能用于修饰一个Annotation定义，用于指定该Annotation可以保留多长时间，@Retention包含一个RetentionPolicy类型的value成员变量，所以使用@Retention时必须为该value成员变量指定值。
value成员变量的值只能是如下三个：
RetentionPolicy.CLASS: 编译器将把注释记录在class文件中。当运行Java程序时，JVM不在保留注释，这是默认值。
RetentionPolicy.RUNTIME: 编译器将把注释记录在class文件中。当运行Java程序时，JVM也会保留注释，程序可以通过反射获取该注释。
RetentionPolicy.SOURCE:  注解仅存在于源码中，在class字节码文件中不包含。
<span style="color:red">@Target</span>
@Target也是用于修饰一个Annotation定义，它用于指定被修饰Annotation能用于修饰那些程序元素。@Target Annotation也包含一个名为value的成员变量，该成员变量只能是如下几个：<br>
ElementType.ANNOTATION_TYPE: 指定该策略的Annotation只能修饰Annotation。
ElementType.CONSTRUCTOR:  指定该策略的Annotation能修饰构造器。
ElementType.FIELD:  指定该策略的Annotation只能修饰成员变量。
ElementType.LOCAL_VARIABLE:  指定该策略的Annotation只能修饰局部变量。
ElementType.METHOD: 指定该策略的Annotation只能修饰方法。
ElementType.PACKAGE:  指定该策略的Annotation只能修饰包定义。
ElementType.PARAMETER:  指定该策略的Annotation可以修饰参数。
ElementType.TYPE:  指定该策略的Annotation可以修饰类、接口（包括注释类型）或枚举定义。
<span style="color:red">@Documented</span>
@Documented用于指定该元Annotation修饰的Annotation类将被javadoc工具提取成文档，如果定义Annotation类时使用了@Documented修饰，则所有使用该Annotation修饰的程序元素的API文档中将会包含该Annotation说明。<br>
<span style="color:red">@Inherited</span>
@Inherited 元 Annotation指定被它修饰的Annotation将具有继承性：如果某个类使用了A Annotation（定义该Annotation时使用了@Inherited修饰）修饰，则其子类将自动具有A注释.

### AOP

### 动态代理
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>aop annotation</tag>
      </tags>
  </entry>
  <entry>
    <title>GRPC</title>
    <url>/2018/12/21/java/grpc_java/</url>
    <content><![CDATA[<h4 id="官方文档：http-grpc-mydoc-io"><a href="#官方文档：http-grpc-mydoc-io" class="headerlink" title="官方文档：http://grpc.mydoc.io/"></a>官方文档：<a href="http://grpc.mydoc.io/" target="_blank" rel="noopener">http://grpc.mydoc.io/</a></h4><h3 id="proto文件："><a href="#proto文件：" class="headerlink" title="proto文件："></a>proto文件：</h3><pre>
syntax = "proto3";

//以外部类模式生成
option java_multiple_files = true;
//所在包名
option java_package = "cn.dxh.practice";
//最外层类名称
option java_outer_classname = "PracticeService";

// 定义服务
service UserService {
    //按id查询数据
    rpc FindById (FindByIdRequest) returns (FindByIdResponse) {
    }

    //服务器端流式 RPC
    //    客户端发送一个请求给服务端，可获取一个数据流用来读取一系列消息。客户端从返回的数据流里一直读取直到没有更多消息为止。
    //    通过在 响应 类型前插入 stream 关键字，可以指定一个服务器端的流方法。
    //查询所有符合条件的数据
    rpc FindByAge (FindByAgeRequest) returns (stream UserEntity) {
    }

    //客户端流式 RPC
    //    即客户端用提供的一个数据流写入并发送一系列消息给服务端。
    //    客户端写入一个消息序列并将其发送到服务器，同样也是使用流。一旦客户端完成消息写入，就等待服务端读取这些消息并返回应答。
    //    通过在 请求 类型前指定 stream 关键字来指定一个客户端的流方法。
    //删除数据
    rpc DeleteById (DeletedByIdRequest) returns (DeletedByIdResponse) {
    }

    //双向流式 RPC
    //    即两边都可以分别通过一个读写数据流来发送一系列消息。这两个数据流操作是相互独立的，所以客户端和服务端能按其希望的任意顺序读写，
    //    例如：服务端可以在写应答前等待所有的客户端消息，或者它可以先读一个消息再写一个消息，或者是读写相结合的其他方式。每个数据流里消息的顺序会被保持。
    //通过在请求和响应前加 stream 关键字去制定方法的类型。
    rpc FindByName (stream FindByNameRequest) returns (stream UserEntity) {
    }
}

//按id查询数据参数
message FindByIdRequest {
    int64 id = 1;
}
//按id查询数据返回结果
message FindByIdResponse {
    string name = 2;
    int32 age = 3;
}
//查询语句的条件参数
message FindByAgeRequest {
    int32 age = 1;
}

//删除数据的参数
message DeletedByIdRequest {
    int64 id = 1;
}

//删除数据的返回结果
message DeletedByIdResponse {
}

//参数
message FindByNameRequest {
}

//实例
message UserEntity {
    int64 id = 1;
    string name = 2;
    int32 age = 3;
    string from = 4;
    string pwd = 5;
}

</pre>

<h3 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h3><h4 id="编写serviceImpl类"><a href="#编写serviceImpl类" class="headerlink" title="编写serviceImpl类"></a>编写serviceImpl类</h4><p> 此类需要继承 UserServiceGrpc.UserServiceImplBase ,这个类提供了我们定义的接口，继承后并覆盖需要实现的方法。</p>
<pre>
@Slf4j
@Service
public class UserServiceImpl extends UserServiceGrpc.UserServiceImplBase {

  @Resource
  private UserMapper userMapper;

  /**
   * 简单rpc
   * 其中StreamObserver<UserEntity>是一个应答观察者,用于封装返回的信息,服务器把该信息传给客户端.请求结束要调用onCompleted()方法.
   * @param request
   * @param responseObserver
   */
  @Override
  public void findById(FindByIdRequest request, StreamObserver<UserEntity> responseObserver) {
    try {
      long id = request.getId();
      userMapper.findById(id)
      responseObserver.onNext(UserEntity.newBuilder().build());
//      请求结束
      responseObserver.onCompleted();
    } catch (Exception e) {
      log.error("findById is error");
    }
  }

  /**
   * 服务器端流式 RPC
   *
   * @param request
   * @param responseObserver
   */
  @Override
  public void findByAge(FindByAgeRequest request, StreamObserver<UserEntity> responseObserver) {
    try {
      int age = request.getAge();
      List<UserEntity> userEntities = userMapper.findByAgs(age);
      userEntities.forEach(userEntity -> responseObserver.onNext(UserEntity.newBuilder().build()));
      responseObserver.onCompleted();
    } catch (Exception e) {
      log.error("");
    }
  }


  /**
   * 客户端流式 RPC
   * 服务端就需要一直监控客户端写入情况,因此需要一个StreamObserver接口,其中onNext方法会在客户端每次写入时调用,当写入完毕时调用onCompleted()方法
   * @param responseObserver
   * @return
   */
  @Override
  public StreamObserver<DeletedByIdRequest> deleteById(StreamObserver<DeletedByIdResponse> responseObserver) {
    return new StreamObserver<DeletedByIdRequest>() {
      @Override
      public void onNext(DeletedByIdRequest deletedByIdRequest) {
        userMapper.deletedById(deletedByIdRequest.getId());
      }

      @Override
      public void onError(Throwable throwable) {
        throwable.printStackTrace();
      }

      @Override
      public void onCompleted() {
        responseObserver.onNext(DeletedByIdResponse.newBuilder().build());
        responseObserver.onCompleted();
      }
    };
  }

  /**
   * 双向流式 RPC
   *
   * @param responseObserver
   * @return
   */
  @Override
  public StreamObserver<FindByNameRequest> findByName(StreamObserver<UserEntity> responseObserver) {
    return new StreamObserver<FindByNameRequest>() {
      @Override
      public void onNext(FindByNameRequest findByNameRequest) {
        userMapper.findByName(findByNameRequest.getName());
      }

      @Override
      public void onError(Throwable throwable) {
        throwable.printStackTrace();
      }

      @Override
      public void onCompleted() {
        responseObserver.onNext(UserEntity.newBuilder().build());
        responseObserver.onCompleted();
      }
    };
  }
}
</pre>

<h4 id="创建服务端"><a href="#创建服务端" class="headerlink" title="创建服务端"></a>创建服务端</h4><pre>
@Component
public class GrpcService {

  private int port = 19090;
  private Server server;

  @Resource
  private UserServiceGrpc.UserServiceImplBase userService;

  @PostConstruct
  public void init() throws IOException {
    ThreadFactory threadFactory = new ThreadFactoryBuilder().setDaemon(true)
                                                            .setNameFormat("grpc-server-thread-%d")
                                                            .build();
    ThreadPoolExecutor executor = new ThreadPoolExecutor(10,
                                                         100,
                                                         60L,
                                                         TimeUnit.SECONDS,
                                                         new LinkedBlockingQueue<>(),
                                                         threadFactory,
                                                         new ThreadPoolExecutor.CallerRunsPolicy());
    server = ServerBuilder.forPort(port)
                          .addService(userService)
                          .executor(executor).build();
    server.start();
  }

  @PreDestroy
  public void destroy() {
    if (server != null) {
      server.shutdown();
    }
  }

}
</pre>

<h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3>]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>rpc grpc</tag>
      </tags>
  </entry>
  <entry>
    <title>jstack (查看线程状态) jmap（查看内存）jstat（性能分析）</title>
    <url>/2019/06/14/jvm/jstack_jmap_jstat/</url>
    <content><![CDATA[<h3 id="基本命令的使用"><a href="#基本命令的使用" class="headerlink" title="基本命令的使用"></a>基本命令的使用</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">获取垃圾回收器的类型和系统参数 &#x2F;&#x2F; jmap -heap pid  </span><br><span class="line">查看应用启动的参数&#x2F;&#x2F; jinfo -flags pid  </span><br><span class="line">查看当前各个代区的容量和使用量情况 &#x2F;&#x2F; jstat  </span><br><span class="line">FGC、YGC的总次数和总耗时 &#x2F;&#x2F; jstat  </span><br><span class="line">立即生成Dump文件 &#x2F;&#x2F;jmap -dump:live,file&#x3D;dump_001.bin PID  </span><br><span class="line">强制FullGC &#x2F;&#x2F; jmap -dump:live  </span><br><span class="line">查看线程的运行信息（包括死锁的线程) &#x2F;&#x2F; jstack -l pid</span><br></pre></td></tr></table></figure>


<h3 id="jstack"><a href="#jstack" class="headerlink" title="jstack"></a>jstack</h3><p>  jstack是jdk自带的线程堆栈分析工具，使用该命令可以查看或导出 Java 应用程序中线程堆栈信息。 </p>
<ul>
<li>功能<br>jstack用于生成java虚拟机当前时刻的线程快照。线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。 如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。    </li>
<li>线程的状态<br>NEW,未启动的。不会出现在Dump中。<br>RUNNABLE,在虚拟机内执行的。<br>BLOCKED,受阻塞并等待监视器锁。<br>WATING,无限期等待另一个线程执行特定操作。<br>TIMED_WATING,有时限的等待另一个线程的特定操作。<br>TERMINATED,已退出的。    </li>
<li>命令<br>jstack -l pid<br>获取pid：ps -ef | grep “name” | grep -v grep | awk ‘{print $2}’<br>pid转16进制：echo ‘ibase=10;ibase=16;pid’|bc</li>
</ul>
<h3 id="jmap"><a href="#jmap" class="headerlink" title="jmap"></a>jmap</h3><p>  jmap heap pid：查看 JDK的概况的最好的一个参数<br>  Jmap是一个可以输出所有内存中对象的工具，甚至可以将VM 中的heap，以二进制输出成文本.<br>  jmap -dump:format=b,file=outfile PID 可以将指定进程的内存heap输出出来到outfile文件里.  </p>
<ul>
<li><p>命令格式<br>jmap [ option ] pid<br>jmap [ option ] executable core<br>jmap [ option ] [server-id@]remote-hostname-or-IP<br>参数说明<br>options：<br>executable :产生core dump的java可执行程序;<br>core 将被打印信息的core dump文件;<br>remote-hostname-or-IP 远程debug服务的主机名或ip;<br>server-id 唯一id,假如一台主机上多个远程debug服务;  </p>
</li>
<li><p>dump 文件分析<br>导出整个JVM 中内存信息： jmap -dump:format=b,file=文件名.dump [pid]</p>
<ul>
<li>将文件远程复制</li>
</ul>
<ol>
<li>将本地文件复制到远程： scp tl.out <a href="mailto:root@47.104.229.246">root@47.104.229.246</a>:/tl.out</li>
<li>将远程文件复制到本地： scp <a href="mailto:root@47.104.229.246">root@47.104.229.246</a>:/root/tl.out tl.out</li>
</ol>
</li>
</ul>
]]></content>
      <categories>
        <category>Jvm</category>
      </categories>
      <tags>
        <tag>jstack jmap jstat</tag>
      </tags>
  </entry>
  <entry>
    <title>dubbo服务的telnet</title>
    <url>/2019/05/23/shell/dubbo_telnet/</url>
    <content><![CDATA[<p>Dubbo2.0.5以上版本服务提供端口支持telnet命令，我们可以进行调试、管理  </p>
<h4 id="1-连接dubbo服务"><a href="#1-连接dubbo服务" class="headerlink" title="1. 连接dubbo服务"></a>1. 连接dubbo服务</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">telnet ip prot</span><br></pre></td></tr></table></figure>
<p>会车进入dubbo命令模式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dubbo&gt;</span><br></pre></td></tr></table></figure>

<h4 id="2-查询服务列表"><a href="#2-查询服务列表" class="headerlink" title="2. 查询服务列表"></a>2. 查询服务列表</h4><ul>
<li><p>查看服务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dubbo&gt; ls</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看服务中的接口</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dubbo&gt; ls 服务地址</span><br></pre></td></tr></table></figure>
</li>
<li><p>ls</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(list services and methods)</span><br><span class="line"></span><br><span class="line">ls</span><br><span class="line">显示服务列表。</span><br><span class="line"></span><br><span class="line">ls -l</span><br><span class="line">显示服务详细信息列表。</span><br><span class="line"></span><br><span class="line">ls XxxService</span><br><span class="line">显示服务的方法列表。</span><br><span class="line"></span><br><span class="line">ls -l XxxService</span><br><span class="line">显示服务的方法详细信息列表。</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="3-调用服务接口"><a href="#3-调用服务接口" class="headerlink" title="3. 调用服务接口"></a>3. 调用服务接口</h4><ul>
<li><p>调用dubbo接口以json格式传参</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dubbo&gt; invoke $&#123;interface&#125;()</span><br></pre></td></tr></table></figure>
</li>
<li><p>invoke</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">invoke XxxService.xxxMethod(&#123;&quot;prop&quot;: &quot;value&quot;&#125;)</span><br><span class="line">调用服务的方法。</span><br><span class="line"></span><br><span class="line">invoke xxxMethod(&#123;&quot;prop&quot;: &quot;value&quot;&#125;)</span><br><span class="line">调用服务的方法(自动查找包含此方法的服务)。</span><br></pre></td></tr></table></figure>
<h4 id="4-查看服务状态"><a href="#4-查看服务状态" class="headerlink" title="4. 查看服务状态"></a>4. 查看服务状态</h4></li>
<li><p>count</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">count XxxService</span><br><span class="line">统计1次服务任意方法的调用情况。</span><br><span class="line"></span><br><span class="line">count XxxService 10</span><br><span class="line">统计10次服务任意方法的调用情况。</span><br><span class="line"></span><br><span class="line">count XxxService xxxMethod</span><br><span class="line">统计1次服务方法的调用情况。</span><br><span class="line"></span><br><span class="line">count XxxService xxxMethod 10</span><br><span class="line">统计10次服务方法的调用情况。</span><br></pre></td></tr></table></figure></li>
<li><p>status</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">status</span><br><span class="line"></span><br><span class="line">显示汇总状态，该状态将汇总所有资源的状态，当全部OK时则显示OK，只要有一个ERROR则显示ERROR，只要有一个WARN则显示WARN。</span><br><span class="line"></span><br><span class="line">status -l</span><br><span class="line">显示状态列表。</span><br></pre></td></tr></table></figure>


















</li>
</ul>
<blockquote>
<p>telnet命令手册: <a href="http://alibaba.github.io/dubbo-doc-static/Telnet+Command+Reference-zh-showComments=true&amp;showCommentArea=true.htm" target="_blank" rel="noopener">http://alibaba.github.io/dubbo-doc-static/Telnet+Command+Reference-zh-showComments=true&amp;showCommentArea=true.htm</a></p>
</blockquote>
]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo telnet</tag>
      </tags>
  </entry>
  <entry>
    <title>shell连接远程服务器脚本</title>
    <url>/2019/07/29/shell/connect_ecs/</url>
    <content><![CDATA[<h3 id="脚本示例"><a href="#脚本示例" class="headerlink" title="脚本示例"></a>脚本示例</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;expect</span><br><span class="line">set timeout 10</span><br><span class="line">set password Dong@0419</span><br><span class="line">spawn ssh root@47.104.229.246 -p 22</span><br><span class="line">expect &#123;</span><br><span class="line">    &quot;password:&quot; &#123;</span><br><span class="line">        send &quot;$&#123;password&#125;\r&quot;;</span><br><span class="line">        exp_continue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">interact</span><br></pre></td></tr></table></figure>

<ul>
<li>第1行：#!/usr/bin/expect  是告诉系统在执行这个脚本的时候用哪个命令来执行，这边是用expect，是一个类似bash和sh的shell。  </li>
<li>第2行 set timeout 10 设置超时时间为10s。  </li>
<li>第3行 set password 123456 定义了一个变量 password，这个变量记录了登陆远程服务器的密码。  </li>
<li>第4行 spawn ssh <a href="mailto:ubuntu@xxx.xxx.xxx.xxx">ubuntu@xxx.xxx.xxx.xxx</a> 调用 spawn 命令来执行一个系统命令。spawn是expect shell的内建命令，只有在expect环境下才可以使用。这行代码的功能就是通过ssh连接远程ECS。  </li>
<li>5~10行 行用了一个 expect 命令，可以将这个命令理解为期待shell中输出结果中包含什么关键字。<br>如果包含的是 password: 则表示不是第一次连接这个远程服务器，直接用send输出密码即可。  </li>
</ul>
]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell编程</title>
    <url>/2019/05/16/shell/shell/</url>
    <content><![CDATA[<p>####### 10进制转16进制: echo ‘ibase=10;ibase=16;{pid}’|bc</p>
<h2 id="shell变量"><a href="#shell变量" class="headerlink" title="shell变量"></a>shell变量</h2><h4 id="定义变量"><a href="#定义变量" class="headerlink" title="定义变量"></a>定义变量</h4><ul>
<li>定义变量时，变量名不加$</li>
<li>命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。</li>
<li>中间不能有空格，可以使用下划线（_）。</li>
<li>不能使用标点符号。</li>
<li>不能使用bash里的关键字（可用help命令查看保留关键字）<h4 id="使用变量"><a href="#使用变量" class="headerlink" title="使用变量"></a>使用变量</h4>使用一个定义过的变量，只要在变量名前面加 $ 即可<br>例如：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">your_name&#x3D;&quot;qinjx&quot;</span><br><span class="line">echo $your_name</span><br><span class="line">echo $&#123;your_name&#125;</span><br></pre></td></tr></table></figure>
已经定义的变量是可以被再次定义的：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">your_name&#x3D;&quot;tom&quot;</span><br><span class="line">echo $your_name</span><br><span class="line">your_name&#x3D;&quot;alibaba&quot;</span><br><span class="line">echo $your_name</span><br></pre></td></tr></table></figure>
注意：再次定义的时候不能使用$  <h4 id="只读变量"><a href="#只读变量" class="headerlink" title="只读变量"></a>只读变量</h4>使用 readonly 命令可以将变量定义为只读变量，只读变量的值不能被改变。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">myUrl&#x3D;&quot;http:&#x2F;&#x2F;www.google.com&quot;</span><br><span class="line">readonly myUrl</span><br></pre></td></tr></table></figure>
<h4 id="删除变量"><a href="#删除变量" class="headerlink" title="删除变量"></a>删除变量</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">variable_name&#x3D;&quot;自定义内容&quot;</span><br><span class="line">unset variable_name</span><br></pre></td></tr></table></figure>
变量被删除后不能再次使用。unset 命令不能删除只读变量。</li>
</ul>
<h4 id="变量类型"><a href="#变量类型" class="headerlink" title="变量类型"></a>变量类型</h4><p>运行shell时，会同时存在三种变量：  </p>
<p>1) 局部变量 局部变量在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。<br>2) 环境变量 所有的程序，包括shell启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候shell脚本也可以定义环境变量。<br>3) shell变量 shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量，有一部分是局部变量，这些变量保证了shell的正常运行</p>
<h3 id="Shell-字符串"><a href="#Shell-字符串" class="headerlink" title="Shell 字符串"></a>Shell 字符串</h3><p>字符串是shell编程中最常用最有用的数据类型（除了数字和字符串，也没啥其它类型好用了），字符串可以用单引号，也可以用双引号，也可以不用引号。  </p>
<h4 id="单引号"><a href="#单引号" class="headerlink" title="单引号"></a>单引号</h4><p>str=’this is a string’<br>单引号字符串的限制：  </p>
<ul>
<li>单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的；</li>
<li>单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。</li>
</ul>
<h4 id="双引号"><a href="#双引号" class="headerlink" title="双引号"></a>双引号</h4><p>例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">your_name&#x3D;&#39;runoob&#39;</span><br><span class="line">str&#x3D;&quot;Hello, I know you are \&quot;$your_name\&quot;! \n&quot;</span><br><span class="line">echo -e $str</span><br><span class="line">输出结果为：</span><br><span class="line">Hello, I know you are &quot;runoob&quot;!</span><br></pre></td></tr></table></figure>
<p>双引号的优点：  </p>
<ul>
<li>双引号里可以有变量</li>
<li>双引号里可以出现转义字符</li>
</ul>
<h4 id="获取字符串长度"><a href="#获取字符串长度" class="headerlink" title="获取字符串长度"></a>获取字符串长度</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">string&#x3D;&quot;abcd&quot;</span><br><span class="line">echo $&#123;#string&#125; #输出 4</span><br></pre></td></tr></table></figure>
<h4 id="提取子字符串"><a href="#提取子字符串" class="headerlink" title="提取子字符串"></a>提取子字符串</h4><p>以下实例从字符串第 2 个字符开始截取 4 个字符：<br> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> #!&#x2F;bin&#x2F;bash</span><br><span class="line">string&#x3D;&quot;runoob is a great site&quot;</span><br><span class="line">echo $&#123;string:1:4&#125; # 输出 unoo</span><br></pre></td></tr></table></figure></p>
<h4 id="查找子字符串"><a href="#查找子字符串" class="headerlink" title="查找子字符串"></a>查找子字符串</h4><p>查找字符 i 或 o 的位置(哪个字母先出现就计算哪个)：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">string&#x3D;&quot;runoob is a great site&quot;</span><br><span class="line">echo &#96;expr index &quot;$string&quot; io&#96;  # 输出 4</span><br></pre></td></tr></table></figure>

<h3 id="Shell-数组"><a href="#Shell-数组" class="headerlink" title="Shell 数组"></a>Shell 数组</h3><p>bash支持一维数组（不支持多维数组），并且没有限定数组的大小。<br>数组元素的下标由 0 开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于 0。</p>
<h4 id="定义数组"><a href="#定义数组" class="headerlink" title="定义数组"></a>定义数组</h4><p>Shell 中，用括号来表示数组，数组元素用”空格”符号分割开。定义数组的一般形式为：<br>数组名=(值1 值2 … 值n)  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> #!&#x2F;bin&#x2F;bash</span><br><span class="line">array_name&#x3D;(value0 value1 value2 value3)</span><br></pre></td></tr></table></figure>
<p>可以不使用连续的下标，而且下标的范围没有限制。</p>
<h4 id="读取数组"><a href="#读取数组" class="headerlink" title="读取数组"></a>读取数组</h4><p>读取数组元素值的一般格式是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$&#123;数组名[下标]&#125;</span><br></pre></td></tr></table></figure>
<p>使用 @ 符号可以获取数组中的所有元素，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo $&#123;array_name[@]&#125;</span><br></pre></td></tr></table></figure>
<h4 id="获取数组的长度"><a href="#获取数组的长度" class="headerlink" title="获取数组的长度"></a>获取数组的长度</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">获取数组长度的方法与获取字符串长度的方法相同，例如：  </span><br><span class="line">取得数组元素的个数  </span><br><span class="line">length&#x3D;$&#123;#array_name[@]&#125;  </span><br><span class="line">或者  </span><br><span class="line">length&#x3D;$&#123;#array_name[*]&#125;  </span><br><span class="line">取得数组单个元素的长度  </span><br><span class="line">lengthn&#x3D;$&#123;#array_name[n]&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Shell-注释"><a href="#Shell-注释" class="headerlink" title="Shell 注释"></a>Shell 注释</h3><p>以 # 开头的行就是注释，会被解释器忽略。</p>
<h4 id="多行注解"><a href="#多行注解" class="headerlink" title="多行注解"></a>多行注解</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">:&lt;&lt;!</span><br><span class="line">...</span><br><span class="line">!</span><br></pre></td></tr></table></figure>

<h2 id="Shell-传递参数"><a href="#Shell-传递参数" class="headerlink" title="Shell 传递参数"></a>Shell 传递参数</h2>]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring事务处理</title>
    <url>/2019/05/17/spring/spring_transaction/</url>
    <content><![CDATA[<h3 id="什么是Spring事务"><a href="#什么是Spring事务" class="headerlink" title="什么是Spring事务"></a>什么是Spring事务</h3><pre>
事务（Transaction）是并发控制的单位，是用户定义的一个操作序列。这些操作要么都做，要么都不做，是一个不可分割的工作单位。
数据库向用户提供保存当前程序状态的方法，叫事务提交（commit）；当事务执行过程中，使数据库忽略当前的状态并回到前面保存的状态的方法叫事务回滚（rollback）
</pre>

<h3 id="事务特性（ACID）"><a href="#事务特性（ACID）" class="headerlink" title="事务特性（ACID）"></a>事务特性（ACID）</h3><p><strong>原子性（atomicity）：</strong> 将事务中所做的操作捆绑成一个原子单元，即对于事务所进行的数据修改等操作，要么全部执行，要么全部不执行。<br><strong>一致性（Consistency)：</strong> 事务在完成时，必须使所有的数据都保持一致状态，而且在相关数据中，所有规则都必须应用于事务的修改，以保持所有数据的完整性。事务结束时，所有的内部数据结构都应该是正确的。<br><strong>隔离性（Isolation）：</strong> 由并发事务所做的修改必须与任何其他事务所做的修改相隔离。事务查看数据时数据所处的状态，要么是被另一并发事务修改之前的状态，要么是被另一并发事务修改之后的状态，即事务不会查看由另一个并发事务正在修改的数据。这种隔离方式也叫可串行性。<br><strong>持久性（Durability）：</strong> 事务完成之后，它对系统的影响是永久的，即使出现系统故障也是如此。  </p>
<h3 id="事务隔离（Isolation-Level）"><a href="#事务隔离（Isolation-Level）" class="headerlink" title="事务隔离（Isolation Level）"></a>事务隔离（Isolation Level）</h3><p>事务隔离意味着对于某个运行着的事务来说，类似于系统中只有一个事物，其他并发事务都不存在一样<br>大部分情况下很少使用安全隔离的事务，但是不完全隔离的事务会带来如下问题：<br><strong>更新丢失（Lost Update）：</strong> 两个事务都企图去更新一行数据，导致事务抛出异常退出。<br><strong>脏数据（Dirty Read）：</strong> 如果第二个应用程序使用了第一个应用程序修改过的数据，而这个数据处于未提交状态，这时就会发生脏读。第一个应用程序随后可能会请求回滚被修改的数据，从而导致第二个事务使用的数据被损坏，即所谓的“变脏”。<br><strong>不可重读（Unrepeatable Read）：</strong> 一个事务两次读同一行数据，可是这两次读到的数据不一样，就叫不可重读。如果一个事务在提交数据之前，另一个事务可以修改和删除这些数据，就会发生不可重读。<br><strong>幻读（Phantom Read）：</strong> 一个事务执行了两次查询，发现第二次查询结果比第一次查询多出了一行，这可能是因为另一个事务在这两次查询之间插入了新行。  </p>
<h4 id="那么为了避免此类问题，提供出了以下隔离级别来防范"><a href="#那么为了避免此类问题，提供出了以下隔离级别来防范" class="headerlink" title="那么为了避免此类问题，提供出了以下隔离级别来防范:"></a>那么为了避免此类问题，提供出了以下隔离级别来防范:</h4><p><strong>读操作未提交（Read Uncommitted）：</strong> 读取未提交的数据是允许的。说明一个事务在提交前，其变化对于其他事务来说是可见的。这样脏读、不可重读和幻读都是允许的。当一个事务已经写入一行数据但未提交，其他事务都不能再写入此行数据；但是，任何事务都可以读任何数据。这个隔离级别使用排写锁实现。<br><strong>读操作已提交（Read Committed）：</strong> 读取未提交的数据是不允许的，它使用临时的共读锁和排写锁实现。这种隔离级别不允许脏读，但不可重读和幻读是允许的。<br><strong>可重读（Repeatable Read）：</strong> 说明事务保证能够再次读取相同的数据而不会失败。此隔离级别不允许脏读和不可重读，但幻读会出现。<br><strong>可串行化（Serializable）：</strong> 提供最严格的事务隔离。这个隔离级别不允许事务并行执行，只允许串行执行。这样，脏读、不可重读或幻读都可发生。  </p>
<h3 id="事务隔离与隔离级别的关系："><a href="#事务隔离与隔离级别的关系：" class="headerlink" title="事务隔离与隔离级别的关系："></a>事务隔离与隔离级别的关系：</h3><table>
<thead>
<tr>
<th align="left">隔离级别</th>
<th align="left">脏读（Dirty Read）</th>
<th align="left">不可重读（Unrepeatable read）</th>
<th align="left">幻读（Phantom Read）</th>
</tr>
</thead>
<tbody><tr>
<td align="left">读操作未提交（Read Uncommitted）</td>
<td align="left">可能</td>
<td align="left">可能</td>
<td align="left">可能</td>
</tr>
<tr>
<td align="left">读操作已提交（Read Committed）</td>
<td align="left">不可能</td>
<td align="left">可能</td>
<td align="left">可能</td>
</tr>
<tr>
<td align="left">可重读（Repeatable Read）</td>
<td align="left">不可能</td>
<td align="left">不可能</td>
<td align="left">可能</td>
</tr>
<tr>
<td align="left">可串行化（Serializable）</td>
<td align="left">不可能</td>
<td align="left">不可能</td>
<td align="left">不可能</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody></table>
<h3 id="事务的传播（Propagation）"><a href="#事务的传播（Propagation）" class="headerlink" title="事务的传播（Propagation）"></a>事务的传播（Propagation）</h3><table>
<thead>
<tr>
<th align="left">事务传播行为类型</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">PROPAGATION_REQUIRED</td>
<td align="left">如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是 最常见的选择。</td>
</tr>
<tr>
<td align="left">PROPAGATION_SUPPORTS</td>
<td align="left">支持当前事务，如果当前没有事务，就以非事务方式执行。</td>
</tr>
<tr>
<td align="left">PROPAGATION_MANDATORY</td>
<td align="left">使用当前的事务，如果当前没有事务，就抛出异常。</td>
</tr>
<tr>
<td align="left">PROPAGATION_REQUIRES_NEW</td>
<td align="left">新建事务，如果当前存在事务，把当前事务挂起。</td>
</tr>
<tr>
<td align="left">PROPAGATION_NOT_SUPPORTED</td>
<td align="left">以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。</td>
</tr>
<tr>
<td align="left">PROPAGATION_NEVER</td>
<td align="left">以非事务方式执行，如果当前存在事务，则抛出异常。</td>
</tr>
<tr>
<td align="left">PROPAGATION_NESTED</td>
<td align="left">如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与 PROPAGATION_REQUIRED 类似的操作。</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody></table>
<p><strong>readOnly</strong> 事务属性中的readOnly标志表示对应的事务应该被最优化为只读事务。这是一个最优化提示 。在一些情况下，一些事务策略能够起到显著的最优化效果，例如在使用Object/Relational映射工具 （如：Hibernate或TopLink）时避免dirty checking（试图“刷新”）。<br><strong>Timeout</strong> 在事务属性中还有定义“timeout”值的选项，指定事务超时为几秒。在JTA中，这将被简单地传递到J2EE服务器的事务协调程序，并据此得到相应的解释。  </p>
<h3 id="事务的嵌套"><a href="#事务的嵌套" class="headerlink" title="事务的嵌套"></a>事务的嵌套</h3><ol>
<li><strong>PROPAGATION_REQUIRED</strong> 加入当前正要执行的事务不在另外一个事务里，那么就起一个新的事务。即，如果存在主事务，则将此事务合并到主事务中，提交和回滚与主事务依赖，不存在主事务则会自起事务。</li>
<li><strong>PROPAGATION_SUPPORTS</strong> 如果当前在事务中，即以事务的形式运行，如果当前不再一个事务中，那么就以非事务的形式运行。</li>
<li><strong>PROPAGATION_MANDATORY</strong> 必须在一个事务中运行。也就是说，他只能被一个父事务调用。否则，他就要抛出异常</li>
<li><strong>PROPAGATION_REQUIRES_NEW</strong> 在主事务中，创建一个新的事务（子事务）并挂起主事务，执行完子事务后，主事务继续执行，但是，如果子事务已经提交，当主事务失败回滚时，子事务是不回滚的</li>
<li><strong>PROPAGATION_NOT_SUPPORTED</strong> 当前不支持事务，当存在事务中时，会将主事务挂起，当以非事务状态执行完后在继续执行主事务</li>
<li><strong>PROPAGATION_NEVER</strong> 不能在事务中运行，否则抛异常。</li>
<li><strong>PROPAGATION_NESTED</strong> 它与PROPAGATION_REQUIRES_NEW的区别是，不另起事务，与主事务相依，而且需要等主事务提交时才会提交，主事务回滚它也回滚。</li>
</ol>
<h3 id="Spring事务处理"><a href="#Spring事务处理" class="headerlink" title="Spring事务处理"></a>Spring事务处理</h3><p> Spring配置文件中关于事务配置总是由三个组成部分，分别是DataSource、TransactionManager和代理机制这三部分，无论哪种配置方式，一般变化的只是代理机制这部分。<br> Spring处理事务主要有五种方法：</p>
<ol>
<li>每个bin都有一个代理</li>
<li>所有bin共享一个代理基类</li>
<li>使用拦截器</li>
<li>使用tx标签配置的拦截器</li>
<li>全注解<br>此处只简单介绍全注解：<br>在配置好数据库配置后，需要 <em>定义事务管理器</em>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;bean id&#x3D;&quot;transactionManager&quot;</span><br><span class="line">        class&#x3D;&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;</span><br><span class="line">    &lt;property name&#x3D;&quot;dataSource&quot; ref&#x3D;&quot;datasource&quot;&#x2F;&gt;</span><br><span class="line">  &lt;&#x2F;bean&gt;</span><br></pre></td></tr></table></figure>
然后在需要事务的方法上添加 @Transactional 注解。  </li>
</ol>
<h3 id="Transactional"><a href="#Transactional" class="headerlink" title="@Transactional"></a>@Transactional</h3><h4 id="Transactional的含义"><a href="#Transactional的含义" class="headerlink" title="@Transactional的含义"></a>@Transactional的含义</h4><p>关键点之一是要考虑两个独立的概念，它们都有各自的范围和生命周期：  </p>
<ul>
<li>persistence context(持久化上下文)</li>
<li>database transaction（事务）<br>@Transactional本身定义了单个事务的范围。这个事务在persistence context的范围内。<br>JPA中的持久化上下文是EntityManager，内部实现使用了Hibernate Session（使用Hibernate作为持久化provider）<br>持久化上下文仅仅是一个同步对象，它记录了有限集合的Java对象的状态，并且保证这些对象的变化最终持久化到数据库。<br>这是与单个事务非常不同的概念。一个Entity Manager可以跨越多个事务使用，而且的确是这样使用的。  <h4 id="EntityManager和Transaction之间的关系"><a href="#EntityManager和Transaction之间的关系" class="headerlink" title="EntityManager和Transaction之间的关系:"></a>EntityManager和Transaction之间的关系:</h4>JPA Entity Manager最常用的方式是“Entity Manager per application transaction”(每个事务都有自己的实体管理器)模式。entity manager注入的常用方法是：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@PersistenceContext</span><br><span class="line">private EntityManager em;</span><br></pre></td></tr></table></figure>
这里默认为“Entity Manager per transaction”模式。这种模式下如果在@Transactional方法内部使用该Entity Manager，那么该方法将在单一事务中运行。  </li>
</ul>
<h4 id="PersistenceContext的工作原理"><a href="#PersistenceContext的工作原理" class="headerlink" title="@PersistenceContext的工作原理"></a>@PersistenceContext的工作原理</h4><p>随之而来的问题就是@PersistenceContext如何仅在容器启动时注入entity manager，假定entity manager生命周期很短暂，而且每次请求需要多个entity manager。<br>答案是它不能：EntityManager是一个接口，注入到spring bean中的不是entity manager本身，而是在运行时代理具体entity manager的context aware proxy（上下文感知代理）。<br>通常用于代理的具体类为SharedEntityManagerInvocationHandler，借助调试器可以确认这一点。  </p>
<h4 id="Transactional如何工作的"><a href="#Transactional如何工作的" class="headerlink" title="@Transactional如何工作的"></a>@Transactional如何工作的</h4><p>实现了EntityManager接口的持久化上下文代理并不是声明式事务管理的唯一部分，事实上包含三个组成部分：</p>
<ul>
<li>EntityManager Proxy本身</li>
<li>事务的切面</li>
<li>事务管理器  <h5 id="事务的切面："><a href="#事务的切面：" class="headerlink" title="事务的切面："></a>事务的切面：</h5>事务的切面是一个“around（环绕）”切面，在注解的业务方法前后都可以被调用。实现切面的具体类是TransactionInterceptor。<br>事务的切面有两个主要职责：  </li>
<li>在’before’时，切面提供一个调用点，来决定被调用业务方法应该在正在进行事务的范围内运行，还是开始一个新的独立事务。  </li>
<li>在’after’时，切面需要确定事务被提交，回滚或者继续运行。  </li>
<li>在’before’时，事务切面自身不包含任何决策逻辑，是否开始新事务的决策委派给事务管理器完成。</li>
</ul>
<h5 id="事务管理器："><a href="#事务管理器：" class="headerlink" title="事务管理器："></a>事务管理器：</h5><p>事务管理器需要解决下面两个问题：    </p>
<ul>
<li>新的Entity Manager是否应该被创建？</li>
<li>是否应该开始新的事务？  </li>
</ul>
<p>这些需要事务切面’before’逻辑被调用时决定。事务管理器的决策基于以下两点：  </p>
<ul>
<li>事务是否正在进行</li>
<li>事务方法的propagation属性（比如REQUIRES_NEW总要开始新事务）  </li>
</ul>
<p>如果事务管理器确定要创建新事务，那么将：  </p>
<ul>
<li>创建一个新的entity manager</li>
<li>entity manager绑定到当前线程</li>
<li>从数据库连接池中获取连接</li>
<li>将连接绑定到当前线程  </li>
</ul>
<blockquote>
<p>摘自：<a href="https://www.cnblogs.com/mxmbk/p/5341258.html" target="_blank" rel="noopener">https://www.cnblogs.com/mxmbk/p/5341258.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring transaction mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat access日志</title>
    <url>/2019/09/26/shell/tomcat_access/</url>
    <content><![CDATA[<h4 id="日志格式配置"><a href="#日志格式配置" class="headerlink" title="日志格式配置"></a>日志格式配置</h4><p>位置在服务下 config/server.xml 中Host标签下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;Host name&#x3D;&quot;localhost&quot;  appBase&#x3D;&quot;webapps&quot;unpackWARs&#x3D;&quot;false&quot; autoDeploy&#x3D;&quot;false&quot;&gt;</span><br><span class="line">    &lt;Valve className&#x3D;&quot;org.apache.catalina.valves.AccessLogValve&quot; directory&#x3D;&quot;logs&quot;</span><br><span class="line">            prefix&#x3D;&quot;access&quot; suffix&#x3D;&quot;.log&quot;</span><br><span class="line">            pattern&#x3D;&quot;%h %l %u %t &quot;%r&quot; %s %b %D&quot;</span><br><span class="line">    &lt;&#x2F;Value&gt;</span><br><span class="line">&lt;&#x2F;Host&gt;</span><br></pre></td></tr></table></figure>
<h4 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h4><table>
<thead>
<tr>
<th align="left">Key</th>
<th align="left">Value</th>
</tr>
</thead>
<tbody><tr>
<td align="left">className</td>
<td align="left">官方文档：This MUST be set to org.apache.catalina.valves.AccessLogValve to use the default access log valve</td>
</tr>
<tr>
<td align="left">directory</td>
<td align="left">日志文件存放的目录。通常设置为tomcat下已有的那个logs文件。</td>
</tr>
<tr>
<td align="left">prefix</td>
<td align="left">日志文件的名称前缀。</td>
</tr>
<tr>
<td align="left">suffix</td>
<td align="left">日志文件的名称后缀。</td>
</tr>
<tr>
<td align="left">pattern</td>
<td align="left">主要参数，见下文</td>
</tr>
<tr>
<td align="left">resolveHosts</td>
<td align="left">如果是true，tomcat会将这个服务器IP地址通过DNS转换为主机名；如果是false，就直接写服务器IP地址啦。默认false。</td>
</tr>
<tr>
<td align="left">rotatable</td>
<td align="left">默认为true，tomcat生成的文件名为prefix（前缀）+.+时间（一般是按天算）+.+suffix（后缀），如：localhost_access_log.2007-09-22.txt。设置为false的话，tomcat会忽略时间，不会生成新文件，文件名就是：localhost_access_log.txt。长此以往，这个日志文件会超级大</td>
</tr>
<tr>
<td align="left">condition</td>
<td align="left">这个参数不太实用，可设置任何值，比如设置成condition=”tkq”，那么只有当ServletRequest.getAttribute(“tkq”)为空的时候，该条日志才会被记录下来</td>
</tr>
<tr>
<td align="left">fileDateFormat</td>
<td align="left">时间格式，是针对日志文件名起作用的。咱们生成的日志文件全名：localhost_access_log.2016-09-22.txt，这里面的2016-09-22就是这么来的。如果想让tomcat每小时生成一个日志文件，也很简单，将这个值设置为：fileDateFormat=”yyyy-MM-dd.HH”</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody></table>
<h4 id="pattern设置"><a href="#pattern设置" class="headerlink" title="pattern设置"></a>pattern设置</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%a   这是记录访问者的IP，在日志里是127.0.0.1</span><br><span class="line">%A   这是记录本地服务器的IP，在日志里是192.168.254.108</span><br><span class="line">%b   发送信息的字节数，不包括http头，如果字节数为0的话，显示为-</span><br><span class="line">%B   发送信息的字节数，不包括http头。</span><br><span class="line">%h   服务器的名称。如果resolveHosts为false的话，这里就是IP地址了，例如我的日志里是10.217.14.16</span><br><span class="line">%H   访问者的协议，这里是HTTP&#x2F;1.0</span><br><span class="line">%l   官方解释：Remote logical username from identd (可能这样翻译：记录浏览者进行身份验证时提供的名字)(always returns &#39;-&#39;)</span><br><span class="line">%m   访问的方式，是GET还是POST</span><br><span class="line">%p   本地接收访问的端口 </span><br><span class="line">%q   比如你访问的是aaa.jsp?bbb&#x3D;ccc，那么这里就显示?bbb&#x3D;ccc，就是querystring的意思</span><br><span class="line">%r   First line of the request (method and request URI) 请求的方法和URL</span><br><span class="line">%s   http的响应状态码 </span><br><span class="line">%S   用户的session ID,这个session ID大家可以另外查一下详细的解释，反正每次都会生成不同的session ID</span><br><span class="line">%t   请求时间</span><br><span class="line">%u   得到了验证的访问者，否则就是&quot;-&quot;</span><br><span class="line">%U   访问的URL地址，我这里是&#x2F;rightmainima&#x2F;leftbott4.swf</span><br><span class="line">%v   服务器名称，可能就是你url里面写的那个吧，我这里是localhost</span><br><span class="line">%D   Time taken to process the request,in millis，请求消耗的时间，以毫秒记</span><br><span class="line">%T   Time taken to process the request,in seconds，请求消耗的时间，以秒记</span><br></pre></td></tr></table></figure>

<h4 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h4><p>awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。<br>使用格式：awk ‘{pattern + action}’ {filenames}  </p>
<ul>
<li>awk内置变量<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ARGC               命令行参数个数</span><br><span class="line">ARGV               命令行参数排列</span><br><span class="line">ENVIRON            支持队列中系统环境变量的使用</span><br><span class="line">FILENAME           awk浏览的文件名</span><br><span class="line">FNR                浏览文件的记录数</span><br><span class="line">FS                 设置输入域分隔符，等价于命令行 -F选项</span><br><span class="line">NF                 浏览记录的域的个数</span><br><span class="line">NR                 已读的记录数</span><br><span class="line">OFS                输出域分隔符</span><br><span class="line">ORS                输出记录分隔符</span><br><span class="line">RS                 控制记录分隔符</span><br><span class="line">$0变量是指整条记录。$1表示当前行的第一个域,$2表示当前行的第二个域,......以此类推。</span><br><span class="line">$NF是number finally,表示最后一列的信息，跟变量NF是有区别的，变量NF统计的是每行列的总数</span><br></pre></td></tr></table></figure></li>
</ul>
<ol>
<li>按条件查询<br>awk ‘{if($13&gt;3000){print $0}}’ |more -10</li>
<li>按时间查询：<br>awk ‘{split($4,array,”[“);if(array[2]&gt;=”26/Sep/2019:17:40:00” &amp;&amp; array[2]&lt;=”26/Sep/2019:17:41:00”){print $0}}’ access.2019-09-26.log |more -10</li>
</ol>
]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring MVC 工作原理和内部流程</title>
    <url>/2019/08/23/spring/spring_mvc/</url>
    <content><![CDATA[<p>Spring MVC 工作原理图</p>
<h3 id="SpringMVC流程"><a href="#SpringMVC流程" class="headerlink" title="SpringMVC流程"></a>SpringMVC流程</h3><p>1、用户发送请求至前端控制器DispatcherServlet。<br>2、DispatcherServlet收到请求调用HandlerMapping处理器映射器。<br>3、处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。<br>4、DispatcherServlet调用HandlerAdapter处理器适配器。<br>5、HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。<br>6、Controller执行完成返回ModelAndView。<br>7、HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。<br>8、DispatcherServlet将ModelAndView传给ViewReslover视图解析器。<br>9、ViewReslover解析后返回具体View。<br>10、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。<br>11、DispatcherServlet响应用户。 </p>
<h3 id="组件说明："><a href="#组件说明：" class="headerlink" title="组件说明："></a>组件说明：</h3><p>以下组件通常使用框架提供实现:<br>DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。<br>HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等.<br>HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器。<br>ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。  </p>
<h3 id="组件："><a href="#组件：" class="headerlink" title="组件："></a>组件：</h3><ol>
<li>前端控制器DispatcherServlet（不需要工程师开发）,由框架提供  </li>
</ol>
<ul>
<li>作用：接收请求，响应结果，相当于转发器，中央处理器。<br>有了dispatcherServlet减少了其它组件之间的耦合度。用户请求到达前端控制器，它就相当于mvc模式中的c，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性。  </li>
</ul>
<ol start="2">
<li>处理器映射器HandlerMapping(不需要工程师开发),由框架提供  </li>
</ol>
<ul>
<li>作用：根据请求的url查找Handler<br>HandlerMapping负责根据用户请求找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。</li>
</ul>
<ol start="3">
<li>处理器适配器HandlerAdapter  </li>
</ol>
<ul>
<li>作用：按照特定规则（HandlerAdapter要求的规则）去执行Handler<br>通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。  </li>
</ul>
<ol start="4">
<li>处理器Handler(需要工程师开发)  </li>
</ol>
<ul>
<li>注意：编写Handler时按照HandlerAdapter的要求去做，这样适配器才可以去正确执行Handler<br>Handler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。<br>由于Handler涉及到具体的用户业务请求，所以一般情况需要工程师根据业务需求开发Handler。  </li>
</ul>
<ol start="5">
<li>视图解析器View resolver(不需要工程师开发),由框架提供  </li>
</ol>
<ul>
<li>作用：进行视图解析，根据逻辑视图名解析成真正的视图（view）<br>View Resolver负责将处理结果生成View视图，View Resolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 springmvc框架提供了很多的View视图类型，包括：jstlView、freemarkerView、pdfView等。<br>一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由工程师根据业务需求开发具体的页面。  </li>
</ul>
<ol start="6">
<li>视图View(需要工程师开发jsp…)<br>View是一个接口，实现类支持不同的View类型（jsp、freemarker、pdf…）  <h4 id="核心架构的具体流程步骤如下："><a href="#核心架构的具体流程步骤如下：" class="headerlink" title="核心架构的具体流程步骤如下："></a>核心架构的具体流程步骤如下：</h4></li>
<li>首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制；</li>
<li>DispatcherServlet——&gt;HandlerMapping， HandlerMapping 将会把请求映射为HandlerExecutionChain 对象（包含一个Handler 处理器（页面控制器）对象、多个HandlerInterceptor 拦截器）对象，通过这种策略模式，很容易添加新的映射策略；</li>
<li>DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter 将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器；</li>
<li>HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter 将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个ModelAndView 对象（包含模型数据、逻辑视图名）；</li>
<li>ModelAndView的逻辑视图名——&gt; ViewResolver， ViewResolver 将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术；</li>
<li>View——&gt;渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构，因此很容易支持其他视图技术；</li>
<li>返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户，到此一个流程结束。<h4 id="下边两个组件通常情况下需要开发："><a href="#下边两个组件通常情况下需要开发：" class="headerlink" title="下边两个组件通常情况下需要开发："></a>下边两个组件通常情况下需要开发：</h4></li>
</ol>
<ul>
<li>Handler：处理器，即后端控制器用controller表示。  </li>
<li>View：视图，即展示给用户的界面，视图中通常需要标签语言展示模型数据。  </li>
</ul>
<p>在将SpringMVC之前我们先来看一下什么是MVC模式<br>MVC：MVC是一种设计模式<br>MVC的原理图：<br><img src="picture/mvc.png" alt="">  </p>
<h4 id="分析："><a href="#分析：" class="headerlink" title="分析："></a>分析：</h4><ul>
<li>M-Model 模型（完成业务逻辑：有javaBean构成，service+dao+entity）  </li>
<li>V-View 视图（做界面的展示  jsp，html……）  </li>
<li>C-Controller 控制器（接收请求—&gt;调用模型—&gt;根据结果派发页面）  </li>
</ul>
<h4 id="springMVC是什么"><a href="#springMVC是什么" class="headerlink" title="springMVC是什么"></a>springMVC是什么</h4><p>　　springMVC是一个MVC的开源框架，springMVC=struts2+spring，springMVC就相当于是Struts2加上sring的整合，但是这里有一个疑惑就是，springMVC和spring是什么样的关系呢？这个在百度百科上有一个很好的解释：意思是说，springMVC是spring的一个后续产品，其实就是spring在原有基础上，又提供了web应用的MVC模块，可以简单的把springMVC理解为是spring的一个模块（类似AOP，IOC这样的模块），网络上经常会说springMVC和spring无缝集成，其实springMVC就是spring的一个子模块，所以根本不需要同spring进行整合。  </p>
<p>SpringMVC的原理图：<br><img src="picture/spring_mvc.png" alt=""><br>看到这个图大家可能会有很多的疑惑，现在我们来看一下这个图的步骤：（可以对比MVC的原理图进行理解）  </p>
<ul>
<li>第一步:用户发起请求到前端控制器（DispatcherServlet）  </li>
<li>第二步：前端控制器请求处理器映射器（HandlerMappering）去查找处理器（Handle）：通过xml配置或者注解进行查找  </li>
<li>第三步：找到以后处理器映射器（HandlerMappering）像前端控制器返回执行链（HandlerExecutionChain）  </li>
<li>第四步：前端控制器（DispatcherServlet）调用处理器适配器（HandlerAdapter）去执行处理器（Handler）  </li>
<li>第五步：处理器适配器去执行Handler  </li>
<li>第六步：Handler执行完给处理器适配器返回ModelAndView  </li>
<li>第七步：处理器适配器向前端控制器返回ModelAndView  </li>
<li>第八步：前端控制器请求视图解析器（ViewResolver）去进行视图解析  </li>
<li>第九步：视图解析器像前端控制器返回View  </li>
<li>第十步：前端控制器对视图进行渲染  </li>
<li>第十一步：前端控制器向用户响应结果  </li>
</ul>
<p>看到这些步骤我相信大家很感觉非常的乱，这是正常的，但是这里主要是要大家理解springMVC中的几个组件：  </p>
<ul>
<li>前端控制器（DispatcherServlet）：接收请求，响应结果，相当于电脑的CPU。  </li>
<li>处理器映射器（HandlerMapping）：根据URL去查找处理器  </li>
<li>处理器（Handler）：（需要程序员去写代码处理逻辑的）  </li>
<li>处理器适配器（HandlerAdapter）：会把处理器包装成适配器，这样就可以支持多种类型的处理器，类比笔记本的适配器（适配器模式的应用）  </li>
<li>视图解析器（ViewResovler）：进行视图解析，多返回的字符串，进行处理，可以解析成对应的页面  </li>
</ul>
<blockquote>
<p>摘自：<a href="https://www.cnblogs.com/xiaoxi/p/6164383.html" target="_blank" rel="noopener">https://www.cnblogs.com/xiaoxi/p/6164383.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring mvc</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch 7.x 修改分词</title>
    <url>/2020/07/01/es/es7/</url>
    <content><![CDATA[<h3 id="Elasticsearch-7-x"><a href="#Elasticsearch-7-x" class="headerlink" title="Elasticsearch(7.x)"></a>Elasticsearch(7.x)</h3><p>官网：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.5/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.5/index.html</a></p>
<h3 id="elastic-默认分词器"><a href="#elastic-默认分词器" class="headerlink" title="elastic 默认分词器"></a>elastic 默认分词器</h3><h3 id="template-index的创建以及分词修改"><a href="#template-index的创建以及分词修改" class="headerlink" title="template,index的创建以及分词修改"></a>template,index的创建以及分词修改</h3><ul>
<li><p>PUT _template</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;_template&#x2F;my_test</span><br><span class="line">&#123;</span><br><span class="line">&quot;template&quot;: &quot;my_test-*&quot;,</span><br><span class="line">&quot;order&quot;: 1,</span><br><span class="line">&quot;settings&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &#123;</span><br><span class="line">    &quot;number_of_shards&quot;: &quot;3&quot;,</span><br><span class="line">    &quot;number_of_replicas&quot;: &quot;1&quot;,</span><br><span class="line">    &quot;store&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;niofs&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;_source&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: &quot;true&quot; </span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;dynamic_templates&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">        &quot;stringType&quot;: &#123;</span><br><span class="line">            &quot;mapping&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;match_mapping_type&quot;: &quot;string&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;properties&quot;:&#123;</span><br><span class="line">        &quot;name&quot;: &#123;</span><br><span class="line">            &quot;analyzer&quot;: &quot;ik_max_word&quot;,  &#x2F;&#x2F;指定分词</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;aliases&quot;: &#123;&#125;  &#x2F;&#x2F;设置别名</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>PUT index</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;my_test-1</span><br><span class="line">&#123;</span><br><span class="line">&quot;settings&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &#123;</span><br><span class="line">    &quot;number_of_shards&quot;: &quot;3&quot;,</span><br><span class="line">    &quot;number_of_replicas&quot;: &quot;1&quot;,</span><br><span class="line">    &quot;store&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;niofs&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;_source&quot;: &#123;</span><br><span class="line">    &quot;includes&quot;: [</span><br><span class="line">        &quot;name&quot;     &#x2F;&#x2F;指定索引文本字段</span><br><span class="line">    ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;dynamic_templates&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;stringType&quot;: &#123;</span><br><span class="line">        &quot;match_mapping_type&quot;: &quot;string&quot;,</span><br><span class="line">        &quot;mapping&quot;: &#123;</span><br><span class="line">            &quot;index&quot;: false,</span><br><span class="line">            &quot;store&quot;: false,</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">        &quot;fields&quot;: &#123;</span><br><span class="line">        &quot;std&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;analyzer&quot;: &quot;standard&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;analyzer&quot;: &quot;ik_max_word&quot;  &#x2F;&#x2F;指定分词</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>给指定index添加新的分词（ngram）</p>
</li>
</ul>
<ol>
<li>首先将分词加入setting中，修改是需要将index 关闭 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POST my_test-2&#x2F;_close</span><br><span class="line">POST my_test-2&#x2F;_open</span><br></pre></td></tr></table></figure></li>
<li>添加分词 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;my_test-1&#x2F;_settings</span><br><span class="line">&#123;</span><br><span class="line">&quot;settings&quot;: &#123;</span><br><span class="line">    &quot;analysis&quot;: &#123;</span><br><span class="line">    &quot;analyzer&quot;: &#123;</span><br><span class="line">        &quot;ngram_analyzer&quot;: &#123;</span><br><span class="line">        &quot;tokenizer&quot;: &quot;ngram_tokenizer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;ngram_tokenizer&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;ngram&quot;,</span><br><span class="line">        &quot;min_gram&quot;: 3,</span><br><span class="line">        &quot;max_gram&quot;: 3,</span><br><span class="line">        &quot;token_chars&quot;: [</span><br><span class="line">            &quot;letter&quot;,</span><br><span class="line">            &quot;digit&quot;</span><br><span class="line">        ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ul>
<li><p>将索引中指定字段使用新增加的分词</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT my_test-2&#x2F;_mapping&#x2F;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">        &quot;fields&quot;: &#123;</span><br><span class="line">        &quot;std&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;analyzer&quot;: &quot;standard&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;analyzer&quot;: &quot;ngram_analyzer&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>PUT doc</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT my_test-1&#x2F;_doc&#x2F;[id]?routing&#x3D;[my_test_data-1]</span><br><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>GET search</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET my_test-2&#x2F;_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;size&quot;: 20,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;bool&quot;: &#123;</span><br><span class="line">                &quot;must&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;match&quot;: &#123;</span><br><span class="line">                            &quot;name&quot;: &#123;</span><br><span class="line">                            &quot;query&quot;: &quot;&quot;,</span><br><span class="line">                            &quot;minimum_should_match&quot;: &quot;-25%&quot;,</span><br><span class="line">                            &quot;boost&quot;: 2</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>查看分词结果(ngram和ik——max_word分词)</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;my_test-1&#x2F;_analyze</span><br><span class="line">&#123;</span><br><span class="line">    &quot;tokenizer&quot;: &quot;ngram&quot;,</span><br><span class="line">    &quot;text&quot;:&quot;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET &#x2F;my_test-2&#x2F;_analyze</span><br><span class="line">&#123;</span><br><span class="line">    &quot;analyzer&quot;: &quot;ik_max_word&quot;,</span><br><span class="line">    &quot;text&quot;: &quot;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>指定字段的子field,可以指定不同的分词机制，在search的时候可 name.field 来实现不同分词搜索</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT my_test-1&#x2F;_mapping</span><br><span class="line">&#123;</span><br><span class="line">    &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">            &quot;fields&quot;: &#123;</span><br><span class="line">                &quot;std&quot;: &#123;</span><br><span class="line">                    &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                    &quot;analyzer&quot;: &quot;ngram_analyzer&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;analyzer&quot;: &quot;ik_max_word&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</li>
</ul>
<h3 id="小记"><a href="#小记" class="headerlink" title="小记"></a>小记</h3><pre><code>修改添加到source中的字段的mapping，可通过 POST my_index/_update_by_query?conflicts=proceed 来重新索引数据</code></pre>]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>es</tag>
      </tags>
  </entry>
  <entry>
    <title>ES基础</title>
    <url>/2018/07/19/es/es_basics/</url>
    <content><![CDATA[<h3 id="RestHighLevelClient-6-5"><a href="#RestHighLevelClient-6-5" class="headerlink" title="RestHighLevelClient(6.5)"></a>RestHighLevelClient(6.5)</h3><p>官网：<a href="https://www.elastic.co/guide/en/elasticsearch/client/java-rest/6.5/java-rest-low-usage-initialization.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/client/java-rest/6.5/java-rest-low-usage-initialization.html</a></p>
<p>一 <br><br>RestClient实例可以通过相应的建立 RestClientBuilder的类，通过创建RestClient#builder(HttpHost…) 静态方法。唯一必需的参数是客户端将与之通信的一个或多个主机，作为HttpHost的实例提供 </p>
<pre>
RestClient restClient = RestClient.builder(
    new HttpHost("localhost", 9200, "http"),
    new HttpHost("localhost", 9201, "http")).build();
</pre>
<p>该RestClient班是线程安全的，理想情况下具有相同的生命周期为使用它的应用程序。重要的是它在不再需要时关闭，以便它使用的所有资源得到正确释放，以及底层的http客户端实例及其线程：</p>
<pre>
restClient.close();
</pre>
<p>二 <br><br>RestClientBuilder还允许在构建RestClient实例时可选地设置以下配置参数：</p>
<pre>
RestClientBuilder builder = RestClient.builder(
    new HttpHost("localhost", 9200, "http"));
Header[] defaultHeaders = new Header[]{new BasicHeader("header", "value")};
builder.setDefaultHeaders(defaultHeaders);
</pre>
<p>设置需要随每个请求一起发送的默认标头，以防止必须为每个请求指定它们</p>
<pre>
RestClientBuilder builder = RestClient.builder(
    new HttpHost("localhost", 9200, "http"));
builder.setMaxRetryTimeoutMillis(10000);
</pre>

<p>设置在多次尝试同一请求时应该遵守的超时。默认值为30秒，与默认套接字超时相同。如果自定义套接字超时，则应相应地调整最大重试超时</p>
<pre>
RestClientBuilder builder = RestClient.builder(
        new HttpHost("localhost", 9200, "http"));
builder.setFailureListener(new RestClient.FailureListener() {
    @Override
    public void onFailure(Node node) {

    }
});
</pre>
<p>设置一个侦听器，每次节点出现故障时都会收到通知，以防需要采取措施。启用嗅探失败时在内部使用。</p>
<pre>
RestClientBuilder builder = RestClient.builder(
    new HttpHost("localhost", 9200, "http"));
builder.setNodeSelector(NodeSelector.SKIP_DEDICATED_MASTERS);
</pre>
<p>设置节点选择器以用于过滤客户端将请求发送到客户端本身的节点之间的节点。这有助于防止在启用嗅探时向专用主节点发送请求。默认情况下，客户端向每个配置的节点发送请求。</p>
<pre>
RestClientBuilder builder = RestClient.builder(
        new HttpHost("localhost", 9200, "http"));
builder.setRequestConfigCallback(
    new RestClientBuilder.RequestConfigCallback() {
        @Override
        public RequestConfig.Builder customizeRequestConfig(
                RequestConfig.Builder requestConfigBuilder) {
            return requestConfigBuilder.setSocketTimeout(10000); 
        }
    });
</pre>


<p>设置允许修改默认请求配置的回调（例如，请求超时，身份验证或org.apache.http.client.config.RequestConfig.Builder 允许设置的任何内容 ）</p>
<pre>
RestClientBuilder builder = RestClient.builder（
    new HttpHost（“localhost”，9200，“http”））; 
builder.setHttpClientConfigCallback（new HttpClientConfigCallback（）{ 
        @ 
        Override public HttpAsyncClientBuilder customizeHttpClient（
                HttpAsyncClientBuilder httpClientBuilder）{ 
            return httpClientBuilder.setProxy（
                new HttpHost（“proxy”，9000，“http”））;  
        } 
    };
</pre>

<h4 id="java-使用RestHighLevelClient"><a href="#java-使用RestHighLevelClient" class="headerlink" title="java 使用RestHighLevelClient"></a>java 使用RestHighLevelClient</h4><pre>
SearchSourceBuilder ssb = new SearchSourceBuilder()
ssb.size(100)
//构建搜索的query语句
ssb.query(<span style="color:red">createQuery()</span>)
//设置返回字段包含和不包含哪些字段，可为null
ssb.fetchSource(new String[],new String[])
//设置超时时间
ssb.timeout(new TimeValue(15,TimeUnit.SECONDS))

//定义参数
SearchRequest sr = new SearchRequest(<span style="color:red">getIndex()</span>).routing(queryParam.tenantId)
sr.source(ssb)

//执行获取结果
SearchResponse resp = client.search(sr, RequestOptions.DEFAULT)
</pre>


<h3 id="Es基本操作"><a href="#Es基本操作" class="headerlink" title="Es基本操作"></a>Es基本操作</h3><p><span style="color:red">index</span>（索引）<br>相当于mysql中的数据库<br><span style="color:red">type</span>（类型）<br>相当于mysql中的一张表 (7.x后只有_doc)<br><span style="color:red">document</span>（文档）<br>相当于mysql中的一行（一条记录）<br><span style="color:red">field</span>（域）<br>相当于mysql中的一列（一个字段）<br><span style="color:red">节点</span><br>一个服务器，由一个名字来标识<br><span style="color:red">集群</span><br>一个或多个节点组织在一起<br><span style="color:red">分片</span><br>将一份数据划分为多小份的能力，允许水平分割和扩展容量。多个分片可以响应请求，提高性能和吞吐量</p>
<p>创建一个索引（即创建数据库）：（index_name为索引的名称）<br>PUT index_name<br>{<br>“settings” : {<br>“number_of_shards” : 5,<br>“number_of_replicas” : 1<br>}<br>}</p>
<p><span style="color:red">查看索引信息：</span>（即查看数据库）<br>GET index_name</p>
<p>GET index_name/_settings</p>
<p><span style="color:red">查看映射</span><br>GET index_name/_mapping</p>
<p><span style="color:red">设置映射：</span>(即设置字段类型)<br>PUT index_name<br>{<br>“mappings” : {<br>“type_name” : {<br>“properties” : {<br>“field_name1” : {<br>“type” : “keyword”<br>},<br>“field_name2” : {<br>“type” : “integet”<br>},<br>“field_name3” : {<br>“type” : “text”,<br>“analyzer” : “ik_max_word”<br>}<br>}<br>}<br>}<br>}</p>
<p><span style="color:red">插入文档：</span>（即插入一条数据）<br>可以指定文档id<br>PUT index_name/type_name/id   （相当于PUT 数据库名/表名/id）<br> 也可以不指定id<br>POST index_name/type_name</p>
<p><span style="color:red">查看文档：</span><br>GET index_name/type_name/id<br>查看_source中的部分字段：<br>GET index_name/type_name/id?_source=field1,field2</p>
<p><span style="color:red">修改文档：</span><br>1.一种是通过PUT的全覆盖方式，旧数据将被删除，以新的代替<br>PUT index_name/type_name/id<br>2.另一种是通过POST方式，只对部分字段进行修改.<br>POST index_name/type_name/id/_update<br>{<br>“doc” : {<br>“field_name” : “ “<br>}<br>}</p>
<p><span style="color:red">删除文档：</span><br>DELETE index_name/type_name/id</p>
<p>###安装es<br>gitHub:<br><a href="https://github.com/elastic/elasticsearch" target="_blank" rel="noopener">https://github.com/elastic/elasticsearch</a></p>
<p>@PostConstruct和@PreDestroy这两个作用于Servlet生命周期的注解，实现Bean初始化之前和销毁之前的自定义操作</p>
<p><span style="color:red">下载并解压</span><br>$ wget <a href="https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.5.1.zip" target="_blank" rel="noopener">https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.5.1.zip</a><br>$ unzip elasticsearch-5.5.1.zip<br>$ cd elasticsearch-5.5.1/<br><span style="color:red">启动</span>    ./bin/elasticsearch<br>第一次启动时内存不够，将config中jvm.options中的<br>-Xms512M<br>-Xmx512M</p>
<p>由于需要修改磁盘，所以不能用root用户启动，需要新建用户<br><span style="color:red">创建新用户并赋权限</span><br>第一步：liunx创建新用户  adduser XXX    然后给创建的用户加密码 passwd XXX    输入两次密码。<br>第二步：切换刚才创建的用户 su XXX  然后执行elasticsearch  会显示Permission denied 权限不足。<br>第四步：root给XXX赋权限，chown -R XXX /你的elasticsearch安装目录。</p>
<p><span style="color:red">查看当前节点的所有索引(index)</span><br>curl -X GET ‘<a href="http://localhost:9200/_cat/indices?v" target="_blank" rel="noopener">http://localhost:9200/_cat/indices?v</a><br><span style="color:red">列出每个 Index 所包含的 Type</span><br>curl ‘localhost:9200/_mapping?pretty=true’</p>
<p>curl -<REST Verb> <Node>:<Port>/<Index>/<Type><ID></p>
<p><span style="color:red">创建索引：</span><br>curl -XPUT ‘localhost:9200/dxh?pretty’<br>将一个信息索引到dxh下的ljf类型中，这个文档的id为1：<br>curl -XPUT ‘localhost:9200/dxh/ljf/1?pretty’ -d ‘{ “name”:”dongxiaohua” }’<br><span style="color:red">获取文档：</span></p>
<h3 id="kibana"><a href="#kibana" class="headerlink" title="kibana"></a>kibana</h3><p><span style="color:red">按文档数量降序列出所有文档信息</span><br>GET /_cat/indices?v&amp;s=docs.count:desc<br><span style="color:red">按文档大小降序列出index</span><br>GET /_cat/indices?v&amp;h=i,tm&amp;s=tm:desc</p>
]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>es</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM虚拟机</title>
    <url>/2020/07/03/jvm/jvm_basics/</url>
    <content><![CDATA[<h3 id="jvm虚拟机内存模型图"><a href="#jvm虚拟机内存模型图" class="headerlink" title="jvm虚拟机内存模型图"></a>jvm虚拟机内存模型图</h3><p><img src="../../images/jvm.png" alt="jvm"></p>
]]></content>
      <categories>
        <category>Jvm</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
</search>
